{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8167e6b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision\n",
    "\n",
    "from dsd import DSDTraining\n",
    "from utils import plot_wb, set_all_seed\n",
    "from squeezenet import SqueezeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702b681a-dbf4-42be-b311-364aabdb52b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe0fabe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_cifar10(BATCH_SIZE=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    # Clear downloading message.\n",
    "    clear_output()\n",
    "\n",
    "    # Split dataset into training set and validation set.\n",
    "    train_dataset, val_dataset = random_split(train_dataset, [45000, 5000])\n",
    "\n",
    "    print(\"Image Shape: {}\".format(train_dataset[0][0].shape), end='\\n\\n')\n",
    "    print(\"Training Set:   {} samples\".format(len(train_dataset)))\n",
    "    print(\"Validation Set:   {} samples\".format(len(val_dataset)))\n",
    "    print(\"Test Set:       {} samples\".format(len(test_dataset)))\n",
    "\n",
    "    # Create iterators.\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "\n",
    "    # Delete the data/ folder.\n",
    "    shutil.rmtree('./data')\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97348ccb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape: torch.Size([3, 32, 32])\n",
      "\n",
      "Training Set:   45000 samples\n",
      "Validation Set:   5000 samples\n",
      "Test Set:       10000 samples\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = load_cifar10()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3213f091-6a97-4f13-a299-941c331f0887",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa629f0c-63bc-49a4-bb3f-d2c7141d4584",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a39f619",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 96, 109, 109]          14,208\n",
      "              ReLU-2         [-1, 96, 109, 109]               0\n",
      "         MaxPool2d-3           [-1, 96, 54, 54]               0\n",
      "            Conv2d-4           [-1, 16, 54, 54]           1,552\n",
      "              ReLU-5           [-1, 16, 54, 54]               0\n",
      "            Conv2d-6           [-1, 64, 54, 54]           1,088\n",
      "              ReLU-7           [-1, 64, 54, 54]               0\n",
      "            Conv2d-8           [-1, 64, 54, 54]           9,280\n",
      "              ReLU-9           [-1, 64, 54, 54]               0\n",
      "       FireModule-10          [-1, 128, 54, 54]               0\n",
      "           Conv2d-11           [-1, 16, 54, 54]           2,064\n",
      "             ReLU-12           [-1, 16, 54, 54]               0\n",
      "           Conv2d-13           [-1, 64, 54, 54]           1,088\n",
      "             ReLU-14           [-1, 64, 54, 54]               0\n",
      "           Conv2d-15           [-1, 64, 54, 54]           9,280\n",
      "             ReLU-16           [-1, 64, 54, 54]               0\n",
      "       FireModule-17          [-1, 128, 54, 54]               0\n",
      "        MaxPool2d-18          [-1, 128, 27, 27]               0\n",
      "           Conv2d-19           [-1, 32, 27, 27]           4,128\n",
      "             ReLU-20           [-1, 32, 27, 27]               0\n",
      "           Conv2d-21          [-1, 128, 27, 27]           4,224\n",
      "             ReLU-22          [-1, 128, 27, 27]               0\n",
      "           Conv2d-23          [-1, 128, 27, 27]          36,992\n",
      "             ReLU-24          [-1, 128, 27, 27]               0\n",
      "       FireModule-25          [-1, 256, 27, 27]               0\n",
      "           Conv2d-26           [-1, 32, 27, 27]           8,224\n",
      "             ReLU-27           [-1, 32, 27, 27]               0\n",
      "           Conv2d-28          [-1, 128, 27, 27]           4,224\n",
      "             ReLU-29          [-1, 128, 27, 27]               0\n",
      "           Conv2d-30          [-1, 128, 27, 27]          36,992\n",
      "             ReLU-31          [-1, 128, 27, 27]               0\n",
      "       FireModule-32          [-1, 256, 27, 27]               0\n",
      "        MaxPool2d-33          [-1, 256, 13, 13]               0\n",
      "           Conv2d-34           [-1, 48, 13, 13]          12,336\n",
      "             ReLU-35           [-1, 48, 13, 13]               0\n",
      "           Conv2d-36          [-1, 192, 13, 13]           9,408\n",
      "             ReLU-37          [-1, 192, 13, 13]               0\n",
      "           Conv2d-38          [-1, 192, 13, 13]          83,136\n",
      "             ReLU-39          [-1, 192, 13, 13]               0\n",
      "       FireModule-40          [-1, 384, 13, 13]               0\n",
      "           Conv2d-41           [-1, 48, 13, 13]          18,480\n",
      "             ReLU-42           [-1, 48, 13, 13]               0\n",
      "           Conv2d-43          [-1, 192, 13, 13]           9,408\n",
      "             ReLU-44          [-1, 192, 13, 13]               0\n",
      "           Conv2d-45          [-1, 192, 13, 13]          83,136\n",
      "             ReLU-46          [-1, 192, 13, 13]               0\n",
      "       FireModule-47          [-1, 384, 13, 13]               0\n",
      "           Conv2d-48           [-1, 64, 13, 13]          24,640\n",
      "             ReLU-49           [-1, 64, 13, 13]               0\n",
      "           Conv2d-50          [-1, 256, 13, 13]          16,640\n",
      "             ReLU-51          [-1, 256, 13, 13]               0\n",
      "           Conv2d-52          [-1, 256, 13, 13]         147,712\n",
      "             ReLU-53          [-1, 256, 13, 13]               0\n",
      "       FireModule-54          [-1, 512, 13, 13]               0\n",
      "           Conv2d-55           [-1, 64, 13, 13]          32,832\n",
      "             ReLU-56           [-1, 64, 13, 13]               0\n",
      "           Conv2d-57          [-1, 256, 13, 13]          16,640\n",
      "             ReLU-58          [-1, 256, 13, 13]               0\n",
      "           Conv2d-59          [-1, 256, 13, 13]         147,712\n",
      "             ReLU-60          [-1, 256, 13, 13]               0\n",
      "       FireModule-61          [-1, 512, 13, 13]               0\n",
      "          Dropout-62          [-1, 512, 13, 13]               0\n",
      "           Conv2d-63           [-1, 10, 13, 13]           5,130\n",
      "             ReLU-64           [-1, 10, 13, 13]               0\n",
      "AdaptiveAvgPool2d-65             [-1, 10, 1, 1]               0\n",
      "       SqueezeNet-66                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 740,554\n",
      "Trainable params: 740,554\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 56.54\n",
      "Params size (MB): 2.82\n",
      "Estimated Total Size (MB): 59.94\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = SqueezeNet()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "dsd_model = DSDTraining(model, sparsity=0.3)\n",
    "summary(dsd_model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33290e46-ad4d-428d-8fd7-b6eb6b910525",
   "metadata": {},
   "source": [
    "#### Define Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2af6e12b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(dsd_model.parameters(), lr=0.001, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47ec76c-3643-4f6d-8fa6-753d41523f54",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be00d75f-17d2-45fb-9a42-891cdf4efd82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_dsd(dsd_model, EPOCH_DENSE1, EPOCH_SPARSE, EPOCH_DENSE2, NB_TRAIN_EXAMPLES, NB_VAL_EXAMPLES):\n",
    "    EPOCHS = EPOCH_DENSE1 + EPOCH_SPARSE + EPOCH_DENSE2\n",
    "    train_costs, val_costs = [], []\n",
    "\n",
    "    #Training phase.\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Train Acc':^12} | {'Val Loss':^10} | {'Val Acc':^10} | {'Elapsed':^9}\")\n",
    "        print(\"-\"*85)\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # DSD\n",
    "        if (epoch >= EPOCH_DENSE1 and epoch < EPOCH_DENSE1 + EPOCH_SPARSE):\n",
    "            dsd_model.train_on_sparse = True\n",
    "        else:\n",
    "            dsd_model.train_on_sparse = False\n",
    "\n",
    "        if dsd_model.train_on_sparse:\n",
    "            dsd_model.update_masks()\n",
    "        \n",
    "        # Training\n",
    "        train_loss, correct_train = 0, 0\n",
    "        batch_loss, correct_batch, batch_counts = 0, 0, 0\n",
    "\n",
    "        if device == \"cuda\":\n",
    "            dsd_model.train().cuda()\n",
    "\n",
    "        for step, (inputs, labels) in enumerate(train_loader):\n",
    "\n",
    "            # Load data to GPU.\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass.\n",
    "            prediction = dsd_model(inputs)\n",
    "\n",
    "            # Compute the loss.\n",
    "            loss = criterion(prediction, labels)\n",
    "\n",
    "            # Backward pass.\n",
    "            loss.backward()\n",
    "\n",
    "            # Sparse-phase\n",
    "            if dsd_model.train_on_sparse:\n",
    "                for (w, b), (mask_w, mask_b) in zip(dsd_model.parameters(), dsd_model.masks):\n",
    "                    # Values\n",
    "                    w.data[mask_w] = 0\n",
    "                    b.data[mask_b] = 0\n",
    "                    # Grad\n",
    "                    w.grad.data[mask_w] = 0\n",
    "                    b.grad.data[mask_b] = 0\n",
    "\n",
    "            # Optimize.\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute training accuracy.\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            correct_batch += (predicted == labels).sum().item()\n",
    "\n",
    "            # Compute batch loss.\n",
    "            batch_loss += (loss.data.item() * inputs.shape[0])\n",
    "            train_loss += (loss.data.item() * inputs.shape[0])\n",
    "\n",
    "            # Print the loss values and time elapsed for every 20 batches\n",
    "            if (step % 100 == 0 and step != 0) or (step == len(train_loader) - 1):\n",
    "\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                print(f\"{epoch + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {correct_batch / batch_counts:^12.6f} | {'-':^10} | {'-':^10} |  {time_elapsed:^9.2f}\")\n",
    "                batch_loss, correct_batch, batch_counts = 0, 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "            batch_counts += inputs.shape[0]\n",
    "\n",
    "        train_loss /= NB_TRAIN_EXAMPLES\n",
    "        train_costs.append(train_loss)\n",
    "        train_acc =  correct_train / NB_TRAIN_EXAMPLES\n",
    "\n",
    "        print(\"-\"*85)\n",
    "\n",
    "        # Validation\n",
    "        val_loss = 0\n",
    "        correct_val = 0\n",
    "\n",
    "        if device == \"cuda\":\n",
    "            dsd_model.eval().cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                # Load data to GPU.\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass.\n",
    "                prediction = dsd_model(inputs)\n",
    "\n",
    "                # Compute the loss.\n",
    "                loss = criterion(prediction, labels)\n",
    "\n",
    "                # Compute training accuracy.\n",
    "                _, predicted = torch.max(prediction.data, 1)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "                # Compute batch loss.\n",
    "                val_loss += (loss.data.item() * inputs.shape[0])\n",
    "\n",
    "            val_loss /= NB_VAL_EXAMPLES\n",
    "            val_costs.append(val_loss)\n",
    "            val_acc =  correct_val / NB_VAL_EXAMPLES\n",
    "\n",
    "        time_elapsed = time.time() - t0_epoch\n",
    "\n",
    "        info = \"[Epoch {}/{}]: train_on_sparse = {} | train-loss = {:0.6f} | train-acc = {:0.6f} | val-loss = {:0.6f} | val-acc = {:0.6f} | time_elapsed = {:0.2f}\"\n",
    "        print(info.format(epoch+1, EPOCHS, dsd_model.train_on_sparse, train_loss, train_acc, val_loss, val_acc, time_elapsed))\n",
    "\n",
    "        # Save plots.\n",
    "        if (epoch + 1 == EPOCH_DENSE1):\n",
    "            plot_wb(dsd_model, \"dense1.png\")\n",
    "        elif (epoch + 1 == EPOCH_DENSE1 + EPOCH_SPARSE):\n",
    "            plot_wb(dsd_model, \"sparse.png\")\n",
    "        elif (epoch + 1 == EPOCHS):\n",
    "            plot_wb(dsd_model, \"dense2.png\")\n",
    "\n",
    "    return train_costs, val_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3c76146",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   1    |   100   |   2.325837   |   0.097187   |     -      |     -      |    2.37   \n",
      "   1    |   200   |   2.302793   |   0.097187   |     -      |     -      |    2.34   \n",
      "   1    |   300   |   2.302644   |   0.099062   |     -      |     -      |    2.33   \n",
      "   1    |   400   |   2.302731   |   0.096562   |     -      |     -      |    2.39   \n",
      "   1    |   500   |   2.302469   |   0.100000   |     -      |     -      |    2.36   \n",
      "   1    |   600   |   2.302567   |   0.105625   |     -      |     -      |    2.33   \n",
      "   1    |   700   |   2.302560   |   0.100156   |     -      |     -      |    2.32   \n",
      "   1    |   703   |   1.631607   |   0.041667   |     -      |     -      |    0.07   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 1/13]: train_on_sparse = False | train-loss = 2.302656 | train-acc = 0.099133 | val-loss = 2.302515 | val-acc = 0.101600 | time_elapsed = 17.77\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   2    |   100   |   2.325592   |   0.101875   |     -      |     -      |    2.46   \n",
      "   2    |   200   |   2.302809   |   0.096094   |     -      |     -      |    2.34   \n",
      "   2    |   300   |   2.302491   |   0.105000   |     -      |     -      |    2.32   \n",
      "   2    |   400   |   2.302613   |   0.107813   |     -      |     -      |    2.74   \n",
      "   2    |   500   |   2.302642   |   0.102813   |     -      |     -      |    2.36   \n",
      "   2    |   600   |   2.302726   |   0.097969   |     -      |     -      |    2.36   \n",
      "   2    |   700   |   2.302599   |   0.102188   |     -      |     -      |    2.32   \n",
      "   2    |   703   |   1.630415   |   0.088542   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 2/13]: train_on_sparse = False | train-loss = 2.302632 | train-acc = 0.101889 | val-loss = 2.302547 | val-acc = 0.102400 | time_elapsed = 18.24\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   3    |   100   |   2.325469   |   0.107344   |     -      |     -      |    2.37   \n",
      "   3    |   200   |   2.302749   |   0.096875   |     -      |     -      |    2.34   \n",
      "   3    |   300   |   2.302563   |   0.100469   |     -      |     -      |    2.31   \n",
      "   3    |   400   |   2.302622   |   0.099219   |     -      |     -      |    2.29   \n",
      "   3    |   500   |   2.302571   |   0.095312   |     -      |     -      |    2.30   \n",
      "   3    |   600   |   2.302480   |   0.100312   |     -      |     -      |    2.38   \n",
      "   3    |   700   |   2.302613   |   0.096875   |     -      |     -      |    2.33   \n",
      "   3    |   703   |   1.630985   |   0.072917   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 3/13]: train_on_sparse = False | train-loss = 2.302577 | train-acc = 0.099356 | val-loss = 2.302749 | val-acc = 0.099200 | time_elapsed = 17.66\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   4    |   100   |   2.325595   |   0.101875   |     -      |     -      |    2.34   \n",
      "   4    |   200   |   2.302561   |   0.101875   |     -      |     -      |    2.35   \n",
      "   4    |   300   |   2.302737   |   0.092500   |     -      |     -      |    2.34   \n",
      "   4    |   400   |   2.302693   |   0.097031   |     -      |     -      |    2.31   \n",
      "   4    |   500   |   2.302544   |   0.101250   |     -      |     -      |    2.33   \n",
      "   4    |   600   |   2.302561   |   0.106719   |     -      |     -      |    2.31   \n",
      "   4    |   700   |   2.302613   |   0.098281   |     -      |     -      |    2.28   \n",
      "   4    |   703   |   1.630279   |   0.104167   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 4/13]: train_on_sparse = False | train-loss = 2.302608 | train-acc = 0.099933 | val-loss = 2.302609 | val-acc = 0.099800 | time_elapsed = 17.59\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   5    |   100   |   2.325588   |   0.099687   |     -      |     -      |    2.32   \n",
      "   5    |   200   |   2.302581   |   0.101250   |     -      |     -      |    2.34   \n",
      "   5    |   300   |   2.302534   |   0.095312   |     -      |     -      |    2.33   \n",
      "   5    |   400   |   2.302477   |   0.106250   |     -      |     -      |    2.36   \n",
      "   5    |   500   |   2.302597   |   0.100625   |     -      |     -      |    2.29   \n",
      "   5    |   600   |   2.302831   |   0.087344   |     -      |     -      |    2.31   \n",
      "   5    |   700   |   2.302575   |   0.100312   |     -      |     -      |    2.69   \n",
      "   5    |   703   |   1.631399   |   0.052083   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 5/13]: train_on_sparse = False | train-loss = 2.302596 | train-acc = 0.098467 | val-loss = 2.302476 | val-acc = 0.105000 | time_elapsed = 17.97\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   6    |   100   |   2.325582   |   0.106406   |     -      |     -      |    2.45   \n",
      "   6    |   200   |   2.302570   |   0.098906   |     -      |     -      |    2.35   \n",
      "   6    |   300   |   2.302610   |   0.101875   |     -      |     -      |    2.34   \n",
      "   6    |   400   |   2.302613   |   0.098281   |     -      |     -      |    2.27   \n",
      "   6    |   500   |   2.302543   |   0.100937   |     -      |     -      |    2.31   \n",
      "   6    |   600   |   2.302678   |   0.092813   |     -      |     -      |    2.32   \n",
      "   6    |   700   |   2.302585   |   0.101406   |     -      |     -      |    2.27   \n",
      "   6    |   703   |   1.631247   |   0.046875   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 6/13]: train_on_sparse = True | train-loss = 2.302595 | train-acc = 0.099844 | val-loss = 2.302598 | val-acc = 0.101600 | time_elapsed = 17.60\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   7    |   100   |   2.325517   |   0.103438   |     -      |     -      |    2.31   \n",
      "   7    |   200   |   2.302653   |   0.095781   |     -      |     -      |    2.39   \n",
      "   7    |   300   |   2.302634   |   0.096719   |     -      |     -      |    2.30   \n",
      "   7    |   400   |   2.302637   |   0.098281   |     -      |     -      |    2.26   \n",
      "   7    |   500   |   2.302667   |   0.100469   |     -      |     -      |    2.25   \n",
      "   7    |   600   |   2.302610   |   0.097969   |     -      |     -      |    2.32   \n",
      "   7    |   700   |   2.302597   |   0.098750   |     -      |     -      |    2.25   \n",
      "   7    |   703   |   1.631167   |   0.057292   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 7/13]: train_on_sparse = True | train-loss = 2.302613 | train-acc = 0.098578 | val-loss = 2.302612 | val-acc = 0.099200 | time_elapsed = 17.40\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   8    |   100   |   2.325598   |   0.102500   |     -      |     -      |    2.30   \n",
      "   8    |   200   |   2.302578   |   0.097344   |     -      |     -      |    2.29   \n",
      "   8    |   300   |   2.302609   |   0.097812   |     -      |     -      |    2.30   \n",
      "   8    |   400   |   2.302581   |   0.097344   |     -      |     -      |    2.25   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   8    |   500   |   2.302582   |   0.107031   |     -      |     -      |    2.27   \n",
      "   8    |   600   |   2.302611   |   0.104375   |     -      |     -      |    2.28   \n",
      "   8    |   700   |   2.302572   |   0.102031   |     -      |     -      |    2.30   \n",
      "   8    |   703   |   1.631068   |   0.083333   |     -      |     -      |    0.07   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 8/13]: train_on_sparse = True | train-loss = 2.302587 | train-acc = 0.101111 | val-loss = 2.302527 | val-acc = 0.104000 | time_elapsed = 17.43\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   9    |   100   |   2.325619   |   0.101562   |     -      |     -      |    2.31   \n",
      "   9    |   200   |   2.302515   |   0.103438   |     -      |     -      |    2.25   \n",
      "   9    |   300   |   2.302504   |   0.109063   |     -      |     -      |    2.71   \n",
      "   9    |   400   |   2.302605   |   0.100000   |     -      |     -      |    2.30   \n",
      "   9    |   500   |   2.302581   |   0.096406   |     -      |     -      |    2.32   \n",
      "   9    |   600   |   2.302616   |   0.097969   |     -      |     -      |    2.28   \n",
      "   9    |   700   |   2.302601   |   0.106094   |     -      |     -      |    2.25   \n",
      "   9    |   703   |   1.631046   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 9/13]: train_on_sparse = False | train-loss = 2.302574 | train-acc = 0.101956 | val-loss = 2.302587 | val-acc = 0.098600 | time_elapsed = 17.71\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  10    |   100   |   2.325644   |   0.097187   |     -      |     -      |    2.29   \n",
      "  10    |   200   |   2.302551   |   0.105625   |     -      |     -      |    2.27   \n",
      "  10    |   300   |   2.302643   |   0.093594   |     -      |     -      |    2.30   \n",
      "  10    |   400   |   2.302610   |   0.094375   |     -      |     -      |    2.37   \n",
      "  10    |   500   |   2.302542   |   0.107813   |     -      |     -      |    2.36   \n",
      "  10    |   600   |   2.302540   |   0.104844   |     -      |     -      |    2.40   \n",
      "  10    |   700   |   2.302596   |   0.097031   |     -      |     -      |    2.34   \n",
      "  10    |   703   |   1.631241   |   0.057292   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 10/13]: train_on_sparse = False | train-loss = 2.302587 | train-acc = 0.099867 | val-loss = 2.302630 | val-acc = 0.096000 | time_elapsed = 17.64\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  11    |   100   |   2.325608   |   0.103594   |     -      |     -      |    2.35   \n",
      "  11    |   200   |   2.302599   |   0.103750   |     -      |     -      |    2.32   \n",
      "  11    |   300   |   2.302672   |   0.100469   |     -      |     -      |    2.34   \n",
      "  11    |   400   |   2.302658   |   0.097812   |     -      |     -      |    2.32   \n",
      "  11    |   500   |   2.302610   |   0.095781   |     -      |     -      |    2.30   \n",
      "  11    |   600   |   2.302604   |   0.100156   |     -      |     -      |    2.38   \n",
      "  11    |   700   |   2.302599   |   0.096719   |     -      |     -      |    2.29   \n",
      "  11    |   703   |   1.631124   |   0.057292   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 11/13]: train_on_sparse = False | train-loss = 2.302618 | train-acc = 0.099556 | val-loss = 2.302600 | val-acc = 0.099800 | time_elapsed = 17.60\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  12    |   100   |   2.325602   |   0.093906   |     -      |     -      |    2.29   \n",
      "  12    |   200   |   2.302581   |   0.100625   |     -      |     -      |    2.25   \n",
      "  12    |   300   |   2.302613   |   0.099062   |     -      |     -      |    2.31   \n",
      "  12    |   400   |   2.302624   |   0.099219   |     -      |     -      |    2.47   \n",
      "  12    |   500   |   2.302610   |   0.104063   |     -      |     -      |    2.54   \n",
      "  12    |   600   |   2.302593   |   0.099531   |     -      |     -      |    2.51   \n",
      "  12    |   700   |   2.302608   |   0.098906   |     -      |     -      |    2.29   \n",
      "  12    |   703   |   1.630959   |   0.067708   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 12/13]: train_on_sparse = False | train-loss = 2.302600 | train-acc = 0.099178 | val-loss = 2.302625 | val-acc = 0.096400 | time_elapsed = 17.99\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  13    |   100   |   2.325613   |   0.107500   |     -      |     -      |    2.33   \n",
      "  13    |   200   |   2.302569   |   0.099062   |     -      |     -      |    2.37   \n",
      "  13    |   300   |   2.302510   |   0.100312   |     -      |     -      |    2.27   \n",
      "  13    |   400   |   2.302602   |   0.099844   |     -      |     -      |    2.27   \n",
      "  13    |   500   |   2.302604   |   0.102188   |     -      |     -      |    2.26   \n",
      "  13    |   600   |   2.302583   |   0.098281   |     -      |     -      |    2.26   \n",
      "  13    |   700   |   2.302588   |   0.103594   |     -      |     -      |    2.26   \n",
      "  13    |   703   |   1.631112   |   0.052083   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 13/13]: train_on_sparse = False | train-loss = 2.302578 | train-acc = 0.101311 | val-loss = 2.302581 | val-acc = 0.102400 | time_elapsed = 17.29\n"
     ]
    }
   ],
   "source": [
    "EPOCH_DENSE1 = 5\n",
    "EPOCH_SPARSE = 3\n",
    "EPOCH_DENSE2 = 5\n",
    "NB_TRAIN_EXAMPLES = len(train_loader.dataset)\n",
    "NB_VAL_EXAMPLES = len(val_loader.dataset)\n",
    "\n",
    "set_all_seed(42)\n",
    "train_costs, val_costs = train_dsd(dsd_model, \n",
    "                                   EPOCH_DENSE1, \n",
    "                                   EPOCH_SPARSE, \n",
    "                                   EPOCH_DENSE2, \n",
    "                                   NB_TRAIN_EXAMPLES, \n",
    "                                   NB_VAL_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5843903c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Training/Validation error')\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.plot(train_costs)\n",
    "plt.plot(val_costs)\n",
    "plt.legend(['train-loss', 'val-loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba89b055-c865-46f1-b513-ad370328f91d",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265125a3-1859-48c1-99ec-cf82ff78a405",
   "metadata": {},
   "source": [
    "#### Experiment-1 : Varying Sparsity Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be25f277-3b1c-4242-921b-671eabef3e5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " New Experiment Started....\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   1    |   100   |   2.325603   |   0.100781   |     -      |     -      |    2.35   \n",
      "   1    |   200   |   2.302603   |   0.098281   |     -      |     -      |    2.30   \n",
      "   1    |   300   |   2.302595   |   0.097812   |     -      |     -      |    2.24   \n",
      "   1    |   400   |   2.302576   |   0.100312   |     -      |     -      |    2.29   \n",
      "   1    |   500   |   2.302575   |   0.105000   |     -      |     -      |    2.33   \n",
      "   1    |   600   |   2.302540   |   0.102188   |     -      |     -      |    2.31   \n",
      "   1    |   700   |   2.302557   |   0.102031   |     -      |     -      |    2.31   \n",
      "   1    |   703   |   1.631142   |   0.067708   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 1/13]: train_on_sparse = False | train-loss = 2.302575 | train-acc = 0.100756 | val-loss = 2.302568 | val-acc = 0.100600 | time_elapsed = 17.46\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   2    |   100   |   2.325625   |   0.097656   |     -      |     -      |    2.32   \n",
      "   2    |   200   |   2.302598   |   0.101250   |     -      |     -      |    2.30   \n",
      "   2    |   300   |   2.302492   |   0.103750   |     -      |     -      |    2.32   \n",
      "   2    |   400   |   2.302587   |   0.103906   |     -      |     -      |    2.36   \n",
      "   2    |   500   |   2.302561   |   0.098750   |     -      |     -      |    2.32   \n",
      "   2    |   600   |   2.302597   |   0.098437   |     -      |     -      |    2.29   \n",
      "   2    |   700   |   2.302571   |   0.098750   |     -      |     -      |    2.34   \n",
      "   2    |   703   |   1.630772   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 2/13]: train_on_sparse = False | train-loss = 2.302571 | train-acc = 0.100244 | val-loss = 2.302602 | val-acc = 0.101000 | time_elapsed = 17.57\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   3    |   100   |   2.325568   |   0.111250   |     -      |     -      |    2.31   \n",
      "   3    |   200   |   2.302630   |   0.102344   |     -      |     -      |    2.29   \n",
      "   3    |   300   |   2.302611   |   0.098281   |     -      |     -      |    2.31   \n",
      "   3    |   400   |   2.302524   |   0.101406   |     -      |     -      |    2.28   \n",
      "   3    |   500   |   2.302527   |   0.097656   |     -      |     -      |    2.29   \n",
      "   3    |   600   |   2.302500   |   0.100781   |     -      |     -      |    2.32   \n",
      "   3    |   700   |   2.302567   |   0.102344   |     -      |     -      |    2.31   \n",
      "   3    |   703   |   1.631073   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 3/13]: train_on_sparse = False | train-loss = 2.302558 | train-acc = 0.101889 | val-loss = 2.302639 | val-acc = 0.094400 | time_elapsed = 17.44\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   4    |   100   |   2.325575   |   0.098437   |     -      |     -      |    2.81   \n",
      "   4    |   200   |   2.302548   |   0.105000   |     -      |     -      |    2.33   \n",
      "   4    |   300   |   2.302648   |   0.099844   |     -      |     -      |    2.31   \n",
      "   4    |   400   |   2.302635   |   0.097187   |     -      |     -      |    2.31   \n",
      "   4    |   500   |   2.302550   |   0.093125   |     -      |     -      |    2.39   \n",
      "   4    |   600   |   2.302575   |   0.105625   |     -      |     -      |    2.28   \n",
      "   4    |   700   |   2.302537   |   0.100937   |     -      |     -      |    2.27   \n",
      "   4    |   703   |   1.630537   |   0.083333   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 4/13]: train_on_sparse = False | train-loss = 2.302575 | train-acc = 0.099933 | val-loss = 2.302580 | val-acc = 0.097800 | time_elapsed = 17.99\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   5    |   100   |   2.325616   |   0.099531   |     -      |     -      |    2.32   \n",
      "   5    |   200   |   2.302558   |   0.101094   |     -      |     -      |    2.29   \n",
      "   5    |   300   |   2.302556   |   0.097500   |     -      |     -      |    2.31   \n",
      "   5    |   400   |   2.302480   |   0.107344   |     -      |     -      |    2.32   \n",
      "   5    |   500   |   2.302582   |   0.105156   |     -      |     -      |    2.28   \n",
      "   5    |   600   |   2.302729   |   0.095156   |     -      |     -      |    2.31   \n",
      "   5    |   700   |   2.302573   |   0.101719   |     -      |     -      |    2.35   \n",
      "   5    |   703   |   1.631307   |   0.057292   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 5/13]: train_on_sparse = False | train-loss = 2.302583 | train-acc = 0.100867 | val-loss = 2.302519 | val-acc = 0.104800 | time_elapsed = 17.50\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   6    |   100   |   2.325610   |   0.106563   |     -      |     -      |    2.34   \n",
      "   6    |   200   |   2.302577   |   0.101094   |     -      |     -      |    2.35   \n",
      "   6    |   300   |   2.302584   |   0.101250   |     -      |     -      |    2.32   \n",
      "   6    |   400   |   2.302603   |   0.099062   |     -      |     -      |    2.29   \n",
      "   6    |   500   |   2.302532   |   0.104531   |     -      |     -      |    2.29   \n",
      "   6    |   600   |   2.302660   |   0.092656   |     -      |     -      |    2.31   \n",
      "   6    |   700   |   2.302546   |   0.102656   |     -      |     -      |    2.31   \n",
      "   6    |   703   |   1.631215   |   0.036458   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 6/13]: train_on_sparse = True | train-loss = 2.302585 | train-acc = 0.100822 | val-loss = 2.302624 | val-acc = 0.103600 | time_elapsed = 17.53\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   7    |   100   |   2.325527   |   0.104375   |     -      |     -      |    2.39   \n",
      "   7    |   200   |   2.302601   |   0.094687   |     -      |     -      |    2.28   \n",
      "   7    |   300   |   2.302594   |   0.098594   |     -      |     -      |    2.26   \n",
      "   7    |   400   |   2.302587   |   0.099844   |     -      |     -      |    2.66   \n",
      "   7    |   500   |   2.302627   |   0.101250   |     -      |     -      |    2.37   \n",
      "   7    |   600   |   2.302592   |   0.099219   |     -      |     -      |    2.26   \n",
      "   7    |   700   |   2.302577   |   0.101719   |     -      |     -      |    2.27   \n",
      "   7    |   703   |   1.631131   |   0.057292   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 7/13]: train_on_sparse = True | train-loss = 2.302583 | train-acc = 0.099756 | val-loss = 2.302609 | val-acc = 0.100600 | time_elapsed = 17.81\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   8    |   100   |   2.325600   |   0.099844   |     -      |     -      |    2.34   \n",
      "   8    |   200   |   2.302565   |   0.099219   |     -      |     -      |    2.30   \n",
      "   8    |   300   |   2.302601   |   0.097812   |     -      |     -      |    2.30   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   8    |   400   |   2.302563   |   0.097656   |     -      |     -      |    2.25   \n",
      "   8    |   500   |   2.302569   |   0.110156   |     -      |     -      |    2.28   \n",
      "   8    |   600   |   2.302610   |   0.103125   |     -      |     -      |    2.28   \n",
      "   8    |   700   |   2.302577   |   0.101562   |     -      |     -      |    2.27   \n",
      "   8    |   703   |   1.631020   |   0.062500   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 8/13]: train_on_sparse = True | train-loss = 2.302580 | train-acc = 0.101156 | val-loss = 2.302540 | val-acc = 0.105600 | time_elapsed = 17.33\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   9    |   100   |   2.325621   |   0.097969   |     -      |     -      |    2.36   \n",
      "   9    |   200   |   2.302513   |   0.105938   |     -      |     -      |    2.46   \n",
      "   9    |   300   |   2.302497   |   0.111094   |     -      |     -      |    2.43   \n",
      "   9    |   400   |   2.302600   |   0.097812   |     -      |     -      |    2.31   \n",
      "   9    |   500   |   2.302591   |   0.095469   |     -      |     -      |    2.32   \n",
      "   9    |   600   |   2.302612   |   0.095312   |     -      |     -      |    2.32   \n",
      "   9    |   700   |   2.302585   |   0.107656   |     -      |     -      |    2.33   \n",
      "   9    |   703   |   1.631013   |   0.067708   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 9/13]: train_on_sparse = False | train-loss = 2.302571 | train-acc = 0.101444 | val-loss = 2.302592 | val-acc = 0.096800 | time_elapsed = 17.81\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  10    |   100   |   2.325613   |   0.099062   |     -      |     -      |    2.34   \n",
      "  10    |   200   |   2.302546   |   0.105781   |     -      |     -      |    2.33   \n",
      "  10    |   300   |   2.302614   |   0.099062   |     -      |     -      |    2.31   \n",
      "  10    |   400   |   2.302590   |   0.093594   |     -      |     -      |    2.29   \n",
      "  10    |   500   |   2.302518   |   0.108906   |     -      |     -      |    2.32   \n",
      "  10    |   600   |   2.302537   |   0.103281   |     -      |     -      |    2.31   \n",
      "  10    |   700   |   2.302591   |   0.096250   |     -      |     -      |    2.68   \n",
      "  10    |   703   |   1.631149   |   0.057292   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 10/13]: train_on_sparse = False | train-loss = 2.302570 | train-acc = 0.100644 | val-loss = 2.302623 | val-acc = 0.095400 | time_elapsed = 17.97\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  11    |   100   |   2.325590   |   0.103281   |     -      |     -      |    2.37   \n",
      "  11    |   200   |   2.302571   |   0.105781   |     -      |     -      |    2.32   \n",
      "  11    |   300   |   2.302640   |   0.102188   |     -      |     -      |    2.30   \n",
      "  11    |   400   |   2.302633   |   0.097344   |     -      |     -      |    2.27   \n",
      "  11    |   500   |   2.302592   |   0.094687   |     -      |     -      |    2.26   \n",
      "  11    |   600   |   2.302590   |   0.101250   |     -      |     -      |    2.28   \n",
      "  11    |   700   |   2.302595   |   0.097812   |     -      |     -      |    2.28   \n",
      "  11    |   703   |   1.631093   |   0.057292   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 11/13]: train_on_sparse = False | train-loss = 2.302598 | train-acc = 0.100133 | val-loss = 2.302601 | val-acc = 0.098400 | time_elapsed = 17.38\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  12    |   100   |   2.325594   |   0.092344   |     -      |     -      |    2.32   \n",
      "  12    |   200   |   2.302571   |   0.100781   |     -      |     -      |    2.30   \n",
      "  12    |   300   |   2.302598   |   0.099844   |     -      |     -      |    2.28   \n",
      "  12    |   400   |   2.302609   |   0.099531   |     -      |     -      |    2.28   \n",
      "  12    |   500   |   2.302603   |   0.103750   |     -      |     -      |    2.30   \n",
      "  12    |   600   |   2.302589   |   0.099219   |     -      |     -      |    2.42   \n",
      "  12    |   700   |   2.302599   |   0.099062   |     -      |     -      |    2.27   \n",
      "  12    |   703   |   1.630971   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 12/13]: train_on_sparse = False | train-loss = 2.302591 | train-acc = 0.099111 | val-loss = 2.302631 | val-acc = 0.095200 | time_elapsed = 17.48\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  13    |   100   |   2.325602   |   0.107656   |     -      |     -      |    2.35   \n",
      "  13    |   200   |   2.302564   |   0.100156   |     -      |     -      |    2.31   \n",
      "  13    |   300   |   2.302495   |   0.101562   |     -      |     -      |    2.28   \n",
      "  13    |   400   |   2.302587   |   0.102344   |     -      |     -      |    2.28   \n",
      "  13    |   500   |   2.302602   |   0.100625   |     -      |     -      |    2.27   \n",
      "  13    |   600   |   2.302578   |   0.100156   |     -      |     -      |    2.28   \n",
      "  13    |   700   |   2.302579   |   0.102188   |     -      |     -      |    2.37   \n",
      "  13    |   703   |   1.631117   |   0.052083   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 13/13]: train_on_sparse = False | train-loss = 2.302569 | train-acc = 0.101867 | val-loss = 2.302594 | val-acc = 0.100800 | time_elapsed = 17.45\n",
      "\n",
      " New Experiment Started....\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   1    |   100   |   2.325601   |   0.101875   |     -      |     -      |    2.29   \n",
      "   1    |   200   |   2.302591   |   0.096406   |     -      |     -      |    2.29   \n",
      "   1    |   300   |   2.302585   |   0.097344   |     -      |     -      |    2.69   \n",
      "   1    |   400   |   2.302580   |   0.099531   |     -      |     -      |    2.28   \n",
      "   1    |   500   |   2.302577   |   0.105469   |     -      |     -      |    2.31   \n",
      "   1    |   600   |   2.302537   |   0.103125   |     -      |     -      |    2.31   \n",
      "   1    |   700   |   2.302553   |   0.102188   |     -      |     -      |    2.24   \n",
      "   1    |   703   |   1.631149   |   0.062500   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 1/13]: train_on_sparse = False | train-loss = 2.302572 | train-acc = 0.100667 | val-loss = 2.302569 | val-acc = 0.100400 | time_elapsed = 17.72\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   2    |   100   |   2.325625   |   0.098906   |     -      |     -      |    2.30   \n",
      "   2    |   200   |   2.302599   |   0.098906   |     -      |     -      |    2.27   \n",
      "   2    |   300   |   2.302504   |   0.105000   |     -      |     -      |    2.27   \n",
      "   2    |   400   |   2.302575   |   0.103125   |     -      |     -      |    2.34   \n",
      "   2    |   500   |   2.302552   |   0.099062   |     -      |     -      |    2.28   \n",
      "   2    |   600   |   2.302586   |   0.098125   |     -      |     -      |    2.28   \n",
      "   2    |   700   |   2.302576   |   0.099531   |     -      |     -      |    2.28   \n",
      "   2    |   703   |   1.630825   |   0.083333   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/13]: train_on_sparse = False | train-loss = 2.302569 | train-acc = 0.100289 | val-loss = 2.302598 | val-acc = 0.101400 | time_elapsed = 17.32\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   3    |   100   |   2.325572   |   0.111562   |     -      |     -      |    2.30   \n",
      "   3    |   200   |   2.302611   |   0.101719   |     -      |     -      |    2.35   \n",
      "   3    |   300   |   2.302603   |   0.098906   |     -      |     -      |    2.58   \n",
      "   3    |   400   |   2.302516   |   0.102188   |     -      |     -      |    2.32   \n",
      "   3    |   500   |   2.302513   |   0.097812   |     -      |     -      |    2.32   \n",
      "   3    |   600   |   2.302491   |   0.098750   |     -      |     -      |    2.26   \n",
      "   3    |   700   |   2.302558   |   0.102188   |     -      |     -      |    2.26   \n",
      "   3    |   703   |   1.631072   |   0.083333   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 3/13]: train_on_sparse = False | train-loss = 2.302549 | train-acc = 0.101778 | val-loss = 2.302634 | val-acc = 0.098800 | time_elapsed = 17.70\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   4    |   100   |   2.325557   |   0.097812   |     -      |     -      |    2.30   \n",
      "   4    |   200   |   2.302535   |   0.106875   |     -      |     -      |    2.25   \n",
      "   4    |   300   |   2.302650   |   0.098906   |     -      |     -      |    2.34   \n",
      "   4    |   400   |   2.302624   |   0.097500   |     -      |     -      |    2.34   \n",
      "   4    |   500   |   2.302553   |   0.092031   |     -      |     -      |    2.37   \n",
      "   4    |   600   |   2.302574   |   0.106719   |     -      |     -      |    2.80   \n",
      "   4    |   700   |   2.302534   |   0.101562   |     -      |     -      |    2.36   \n",
      "   4    |   703   |   1.630533   |   0.088542   |     -      |     -      |    0.08   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 4/13]: train_on_sparse = False | train-loss = 2.302570 | train-acc = 0.100133 | val-loss = 2.302584 | val-acc = 0.097200 | time_elapsed = 18.17\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   5    |   100   |   2.325611   |   0.099687   |     -      |     -      |    2.45   \n",
      "   5    |   200   |   2.302555   |   0.101094   |     -      |     -      |    2.34   \n",
      "   5    |   300   |   2.302543   |   0.097031   |     -      |     -      |    2.42   \n",
      "   5    |   400   |   2.302466   |   0.107344   |     -      |     -      |    2.27   \n",
      "   5    |   500   |   2.302567   |   0.105469   |     -      |     -      |    2.25   \n",
      "   5    |   600   |   2.302716   |   0.095937   |     -      |     -      |    2.26   \n",
      "   5    |   700   |   2.302564   |   0.103750   |     -      |     -      |    2.26   \n",
      "   5    |   703   |   1.631338   |   0.046875   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 5/13]: train_on_sparse = False | train-loss = 2.302573 | train-acc = 0.101222 | val-loss = 2.302528 | val-acc = 0.105400 | time_elapsed = 17.56\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   6    |   100   |   2.325610   |   0.109375   |     -      |     -      |    2.29   \n",
      "   6    |   200   |   2.302554   |   0.100469   |     -      |     -      |    2.27   \n",
      "   6    |   300   |   2.302589   |   0.102344   |     -      |     -      |    2.28   \n",
      "   6    |   400   |   2.302601   |   0.097812   |     -      |     -      |    2.26   \n",
      "   6    |   500   |   2.302510   |   0.103906   |     -      |     -      |    2.32   \n",
      "   6    |   600   |   2.302671   |   0.092031   |     -      |     -      |    2.40   \n",
      "   6    |   700   |   2.302535   |   0.103750   |     -      |     -      |    2.26   \n",
      "   6    |   703   |   1.631251   |   0.031250   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 6/13]: train_on_sparse = True | train-loss = 2.302579 | train-acc = 0.101067 | val-loss = 2.302623 | val-acc = 0.104600 | time_elapsed = 17.39\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   7    |   100   |   2.325519   |   0.104063   |     -      |     -      |    2.29   \n",
      "   7    |   200   |   2.302609   |   0.095781   |     -      |     -      |    2.27   \n",
      "   7    |   300   |   2.302593   |   0.098906   |     -      |     -      |    2.31   \n",
      "   7    |   400   |   2.302578   |   0.098750   |     -      |     -      |    2.28   \n",
      "   7    |   500   |   2.302621   |   0.101875   |     -      |     -      |    2.27   \n",
      "   7    |   600   |   2.302594   |   0.099844   |     -      |     -      |    2.27   \n",
      "   7    |   700   |   2.302582   |   0.103594   |     -      |     -      |    2.28   \n",
      "   7    |   703   |   1.631180   |   0.052083   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 7/13]: train_on_sparse = True | train-loss = 2.302582 | train-acc = 0.100178 | val-loss = 2.302612 | val-acc = 0.100800 | time_elapsed = 17.25\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   8    |   100   |   2.325598   |   0.098281   |     -      |     -      |    2.70   \n",
      "   8    |   200   |   2.302560   |   0.099062   |     -      |     -      |    2.29   \n",
      "   8    |   300   |   2.302593   |   0.097812   |     -      |     -      |    2.37   \n",
      "   8    |   400   |   2.302558   |   0.098437   |     -      |     -      |    2.46   \n",
      "   8    |   500   |   2.302555   |   0.111875   |     -      |     -      |    2.33   \n",
      "   8    |   600   |   2.302604   |   0.104531   |     -      |     -      |    2.32   \n",
      "   8    |   700   |   2.302556   |   0.103594   |     -      |     -      |    2.35   \n",
      "   8    |   703   |   1.631011   |   0.067708   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 8/13]: train_on_sparse = True | train-loss = 2.302571 | train-acc = 0.101778 | val-loss = 2.302536 | val-acc = 0.106800 | time_elapsed = 18.15\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   9    |   100   |   2.325633   |   0.098281   |     -      |     -      |    2.29   \n",
      "   9    |   200   |   2.302508   |   0.104844   |     -      |     -      |    2.24   \n",
      "   9    |   300   |   2.302478   |   0.112344   |     -      |     -      |    2.25   \n",
      "   9    |   400   |   2.302612   |   0.101875   |     -      |     -      |    2.27   \n",
      "   9    |   500   |   2.302577   |   0.098281   |     -      |     -      |    2.27   \n",
      "   9    |   600   |   2.302596   |   0.096875   |     -      |     -      |    2.28   \n",
      "   9    |   700   |   2.302577   |   0.105313   |     -      |     -      |    2.25   \n",
      "   9    |   703   |   1.630916   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 9/13]: train_on_sparse = False | train-loss = 2.302565 | train-acc = 0.102422 | val-loss = 2.302607 | val-acc = 0.097400 | time_elapsed = 17.27\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  10    |   100   |   2.325616   |   0.099844   |     -      |     -      |    2.32   \n",
      "  10    |   200   |   2.302542   |   0.108125   |     -      |     -      |    2.42   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10    |   300   |   2.302650   |   0.097187   |     -      |     -      |    2.32   \n",
      "  10    |   400   |   2.302608   |   0.092031   |     -      |     -      |    2.29   \n",
      "  10    |   500   |   2.302491   |   0.109687   |     -      |     -      |    2.31   \n",
      "  10    |   600   |   2.302514   |   0.102031   |     -      |     -      |    2.29   \n",
      "  10    |   700   |   2.302582   |   0.097031   |     -      |     -      |    2.29   \n",
      "  10    |   703   |   1.631181   |   0.052083   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 10/13]: train_on_sparse = False | train-loss = 2.302569 | train-acc = 0.100622 | val-loss = 2.302641 | val-acc = 0.095600 | time_elapsed = 17.54\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  11    |   100   |   2.325590   |   0.101250   |     -      |     -      |    2.33   \n",
      "  11    |   200   |   2.302545   |   0.105156   |     -      |     -      |    2.31   \n",
      "  11    |   300   |   2.302646   |   0.101094   |     -      |     -      |    2.26   \n",
      "  11    |   400   |   2.302634   |   0.096719   |     -      |     -      |    2.68   \n",
      "  11    |   500   |   2.302583   |   0.096250   |     -      |     -      |    2.30   \n",
      "  11    |   600   |   2.302573   |   0.100625   |     -      |     -      |    2.26   \n",
      "  11    |   700   |   2.302600   |   0.095625   |     -      |     -      |    2.34   \n",
      "  11    |   703   |   1.631095   |   0.062500   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 11/13]: train_on_sparse = False | train-loss = 2.302593 | train-acc = 0.099356 | val-loss = 2.302597 | val-acc = 0.100400 | time_elapsed = 17.77\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  12    |   100   |   2.325593   |   0.093906   |     -      |     -      |    2.30   \n",
      "  12    |   200   |   2.302563   |   0.103125   |     -      |     -      |    2.26   \n",
      "  12    |   300   |   2.302594   |   0.100625   |     -      |     -      |    2.31   \n",
      "  12    |   400   |   2.302607   |   0.100156   |     -      |     -      |    2.30   \n",
      "  12    |   500   |   2.302593   |   0.100937   |     -      |     -      |    2.28   \n",
      "  12    |   600   |   2.302601   |   0.097969   |     -      |     -      |    2.27   \n",
      "  12    |   700   |   2.302600   |   0.101875   |     -      |     -      |    2.29   \n",
      "  12    |   703   |   1.630955   |   0.083333   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 12/13]: train_on_sparse = False | train-loss = 2.302589 | train-acc = 0.099711 | val-loss = 2.302617 | val-acc = 0.096000 | time_elapsed = 17.31\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  13    |   100   |   2.325592   |   0.107031   |     -      |     -      |    2.30   \n",
      "  13    |   200   |   2.302556   |   0.097812   |     -      |     -      |    2.28   \n",
      "  13    |   300   |   2.302479   |   0.101719   |     -      |     -      |    2.27   \n",
      "  13    |   400   |   2.302572   |   0.103438   |     -      |     -      |    2.32   \n",
      "  13    |   500   |   2.302606   |   0.098750   |     -      |     -      |    2.41   \n",
      "  13    |   600   |   2.302571   |   0.101406   |     -      |     -      |    2.27   \n",
      "  13    |   700   |   2.302571   |   0.100781   |     -      |     -      |    2.25   \n",
      "  13    |   703   |   1.631119   |   0.052083   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 13/13]: train_on_sparse = False | train-loss = 2.302561 | train-acc = 0.101333 | val-loss = 2.302592 | val-acc = 0.101400 | time_elapsed = 17.37\n",
      "\n",
      " New Experiment Started....\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   1    |   100   |   2.325592   |   0.101875   |     -      |     -      |    2.30   \n",
      "   1    |   200   |   2.302596   |   0.096406   |     -      |     -      |    2.28   \n",
      "   1    |   300   |   2.302581   |   0.097187   |     -      |     -      |    2.28   \n",
      "   1    |   400   |   2.302578   |   0.101562   |     -      |     -      |    2.28   \n",
      "   1    |   500   |   2.302567   |   0.104844   |     -      |     -      |    2.39   \n",
      "   1    |   600   |   2.302529   |   0.103750   |     -      |     -      |    2.28   \n",
      "   1    |   700   |   2.302535   |   0.103906   |     -      |     -      |    2.41   \n",
      "   1    |   703   |   1.631130   |   0.057292   |     -      |     -      |    0.11   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 1/13]: train_on_sparse = False | train-loss = 2.302565 | train-acc = 0.101156 | val-loss = 2.302578 | val-acc = 0.102000 | time_elapsed = 17.76\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   2    |   100   |   2.325616   |   0.098281   |     -      |     -      |    2.33   \n",
      "   2    |   200   |   2.302603   |   0.100937   |     -      |     -      |    2.28   \n",
      "   2    |   300   |   2.302480   |   0.106875   |     -      |     -      |    2.37   \n",
      "   2    |   400   |   2.302571   |   0.103594   |     -      |     -      |    2.32   \n",
      "   2    |   500   |   2.302552   |   0.098437   |     -      |     -      |    2.32   \n",
      "   2    |   600   |   2.302595   |   0.101094   |     -      |     -      |    2.35   \n",
      "   2    |   700   |   2.302560   |   0.101094   |     -      |     -      |    2.29   \n",
      "   2    |   703   |   1.630631   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 2/13]: train_on_sparse = False | train-loss = 2.302563 | train-acc = 0.101356 | val-loss = 2.302605 | val-acc = 0.100800 | time_elapsed = 17.55\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   3    |   100   |   2.325544   |   0.112656   |     -      |     -      |    2.29   \n",
      "   3    |   200   |   2.302610   |   0.102344   |     -      |     -      |    2.26   \n",
      "   3    |   300   |   2.302597   |   0.099062   |     -      |     -      |    2.27   \n",
      "   3    |   400   |   2.302505   |   0.098750   |     -      |     -      |    2.26   \n",
      "   3    |   500   |   2.302506   |   0.099062   |     -      |     -      |    2.27   \n",
      "   3    |   600   |   2.302480   |   0.100781   |     -      |     -      |    2.28   \n",
      "   3    |   700   |   2.302552   |   0.101250   |     -      |     -      |    2.28   \n",
      "   3    |   703   |   1.631055   |   0.083333   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 3/13]: train_on_sparse = False | train-loss = 2.302539 | train-acc = 0.101889 | val-loss = 2.302640 | val-acc = 0.098000 | time_elapsed = 17.23\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   4    |   100   |   2.325545   |   0.098281   |     -      |     -      |    2.44   \n",
      "   4    |   200   |   2.302520   |   0.105000   |     -      |     -      |    2.24   \n",
      "   4    |   300   |   2.302650   |   0.098125   |     -      |     -      |    2.25   \n",
      "   4    |   400   |   2.302631   |   0.097656   |     -      |     -      |    2.26   \n",
      "   4    |   500   |   2.302542   |   0.094687   |     -      |     -      |    2.27   \n",
      "   4    |   600   |   2.302557   |   0.107188   |     -      |     -      |    2.28   \n",
      "   4    |   700   |   2.302517   |   0.102188   |     -      |     -      |    2.24   \n",
      "   4    |   703   |   1.630383   |   0.088542   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/13]: train_on_sparse = False | train-loss = 2.302560 | train-acc = 0.100378 | val-loss = 2.302585 | val-acc = 0.099400 | time_elapsed = 17.27\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   5    |   100   |   2.325612   |   0.099375   |     -      |     -      |    2.27   \n",
      "   5    |   200   |   2.302553   |   0.102031   |     -      |     -      |    2.26   \n",
      "   5    |   300   |   2.302530   |   0.097344   |     -      |     -      |    2.65   \n",
      "   5    |   400   |   2.302449   |   0.106719   |     -      |     -      |    2.26   \n",
      "   5    |   500   |   2.302545   |   0.105156   |     -      |     -      |    2.25   \n",
      "   5    |   600   |   2.302724   |   0.095469   |     -      |     -      |    2.34   \n",
      "   5    |   700   |   2.302546   |   0.104063   |     -      |     -      |    2.38   \n",
      "   5    |   703   |   1.631367   |   0.041667   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 5/13]: train_on_sparse = False | train-loss = 2.302564 | train-acc = 0.101178 | val-loss = 2.302535 | val-acc = 0.105000 | time_elapsed = 17.71\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   6    |   100   |   2.325599   |   0.110156   |     -      |     -      |    2.31   \n",
      "   6    |   200   |   2.302546   |   0.100000   |     -      |     -      |    2.38   \n",
      "   6    |   300   |   2.302581   |   0.100937   |     -      |     -      |    2.27   \n",
      "   6    |   400   |   2.302598   |   0.097656   |     -      |     -      |    2.26   \n",
      "   6    |   500   |   2.302497   |   0.104219   |     -      |     -      |    2.27   \n",
      "   6    |   600   |   2.302673   |   0.093594   |     -      |     -      |    2.29   \n",
      "   6    |   700   |   2.302520   |   0.105000   |     -      |     -      |    2.30   \n",
      "   6    |   703   |   1.631310   |   0.036458   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 6/13]: train_on_sparse = True | train-loss = 2.302571 | train-acc = 0.101356 | val-loss = 2.302629 | val-acc = 0.101800 | time_elapsed = 17.39\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   7    |   100   |   2.325511   |   0.105000   |     -      |     -      |    2.30   \n",
      "   7    |   200   |   2.302613   |   0.096406   |     -      |     -      |    2.29   \n",
      "   7    |   300   |   2.302589   |   0.098906   |     -      |     -      |    2.31   \n",
      "   7    |   400   |   2.302572   |   0.098594   |     -      |     -      |    2.38   \n",
      "   7    |   500   |   2.302611   |   0.102031   |     -      |     -      |    2.41   \n",
      "   7    |   600   |   2.302586   |   0.099531   |     -      |     -      |    2.30   \n",
      "   7    |   700   |   2.302581   |   0.100937   |     -      |     -      |    2.29   \n",
      "   7    |   703   |   1.631210   |   0.052083   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 7/13]: train_on_sparse = True | train-loss = 2.302578 | train-acc = 0.099978 | val-loss = 2.302612 | val-acc = 0.099600 | time_elapsed = 17.58\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   8    |   100   |   2.325598   |   0.098281   |     -      |     -      |    2.29   \n",
      "   8    |   200   |   2.302553   |   0.098906   |     -      |     -      |    2.26   \n",
      "   8    |   300   |   2.302585   |   0.098125   |     -      |     -      |    2.26   \n",
      "   8    |   400   |   2.302551   |   0.098750   |     -      |     -      |    2.26   \n",
      "   8    |   500   |   2.302549   |   0.111875   |     -      |     -      |    2.36   \n",
      "   8    |   600   |   2.302596   |   0.104219   |     -      |     -      |    2.66   \n",
      "   8    |   700   |   2.302551   |   0.102656   |     -      |     -      |    2.43   \n",
      "   8    |   703   |   1.630959   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 8/13]: train_on_sparse = True | train-loss = 2.302565 | train-acc = 0.101711 | val-loss = 2.302532 | val-acc = 0.107400 | time_elapsed = 17.86\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   9    |   100   |   2.325629   |   0.099062   |     -      |     -      |    2.29   \n",
      "   9    |   200   |   2.302505   |   0.105469   |     -      |     -      |    2.35   \n",
      "   9    |   300   |   2.302471   |   0.112187   |     -      |     -      |    2.28   \n",
      "   9    |   400   |   2.302612   |   0.102969   |     -      |     -      |    2.26   \n",
      "   9    |   500   |   2.302560   |   0.097969   |     -      |     -      |    2.33   \n",
      "   9    |   600   |   2.302589   |   0.097344   |     -      |     -      |    2.26   \n",
      "   9    |   700   |   2.302570   |   0.107500   |     -      |     -      |    2.34   \n",
      "   9    |   703   |   1.630901   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 9/13]: train_on_sparse = False | train-loss = 2.302558 | train-acc = 0.103089 | val-loss = 2.302613 | val-acc = 0.099200 | time_elapsed = 17.41\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  10    |   100   |   2.325608   |   0.100000   |     -      |     -      |    2.28   \n",
      "  10    |   200   |   2.302532   |   0.108281   |     -      |     -      |    2.25   \n",
      "  10    |   300   |   2.302653   |   0.097187   |     -      |     -      |    2.28   \n",
      "  10    |   400   |   2.302612   |   0.095312   |     -      |     -      |    2.26   \n",
      "  10    |   500   |   2.302476   |   0.108281   |     -      |     -      |    2.27   \n",
      "  10    |   600   |   2.302493   |   0.101719   |     -      |     -      |    2.27   \n",
      "  10    |   700   |   2.302580   |   0.096562   |     -      |     -      |    2.42   \n",
      "  10    |   703   |   1.631192   |   0.057292   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 10/13]: train_on_sparse = False | train-loss = 2.302562 | train-acc = 0.100844 | val-loss = 2.302646 | val-acc = 0.094400 | time_elapsed = 17.44\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  11    |   100   |   2.325574   |   0.104531   |     -      |     -      |    2.38   \n",
      "  11    |   200   |   2.302538   |   0.105781   |     -      |     -      |    2.26   \n",
      "  11    |   300   |   2.302641   |   0.101406   |     -      |     -      |    2.30   \n",
      "  11    |   400   |   2.302643   |   0.095000   |     -      |     -      |    2.27   \n",
      "  11    |   500   |   2.302579   |   0.093281   |     -      |     -      |    2.26   \n",
      "  11    |   600   |   2.302567   |   0.100312   |     -      |     -      |    2.26   \n",
      "  11    |   700   |   2.302604   |   0.099531   |     -      |     -      |    2.29   \n",
      "  11    |   703   |   1.631155   |   0.052083   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 11/13]: train_on_sparse = False | train-loss = 2.302589 | train-acc = 0.099756 | val-loss = 2.302602 | val-acc = 0.098200 | time_elapsed = 17.32\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  12    |   100   |   2.325592   |   0.096094   |     -      |     -      |    2.31   \n",
      "  12    |   200   |   2.302560   |   0.103906   |     -      |     -      |    2.62   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  12    |   300   |   2.302599   |   0.098594   |     -      |     -      |    2.25   \n",
      "  12    |   400   |   2.302601   |   0.099219   |     -      |     -      |    2.25   \n",
      "  12    |   500   |   2.302582   |   0.101094   |     -      |     -      |    2.28   \n",
      "  12    |   600   |   2.302615   |   0.099219   |     -      |     -      |    2.36   \n",
      "  12    |   700   |   2.302607   |   0.101094   |     -      |     -      |    2.26   \n",
      "  12    |   703   |   1.630942   |   0.088542   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 12/13]: train_on_sparse = False | train-loss = 2.302590 | train-acc = 0.099822 | val-loss = 2.302618 | val-acc = 0.096000 | time_elapsed = 17.62\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  13    |   100   |   2.325592   |   0.103750   |     -      |     -      |    2.29   \n",
      "  13    |   200   |   2.302552   |   0.097031   |     -      |     -      |    2.26   \n",
      "  13    |   300   |   2.302466   |   0.101250   |     -      |     -      |    2.25   \n",
      "  13    |   400   |   2.302566   |   0.102656   |     -      |     -      |    2.27   \n",
      "  13    |   500   |   2.302607   |   0.099219   |     -      |     -      |    2.26   \n",
      "  13    |   600   |   2.302569   |   0.101562   |     -      |     -      |    2.26   \n",
      "  13    |   700   |   2.302568   |   0.100156   |     -      |     -      |    2.25   \n",
      "  13    |   703   |   1.631093   |   0.046875   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 13/13]: train_on_sparse = False | train-loss = 2.302557 | train-acc = 0.100556 | val-loss = 2.302595 | val-acc = 0.101200 | time_elapsed = 17.16\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to perform DSD training with varying sparsity levels\n",
    "def experiment_vary_sparsity(model, sparsity_levels, EPOCH_DENSE1, EPOCH_SPARSE, EPOCH_DENSE2, NB_TRAIN_EXAMPLES, NB_VAL_EXAMPLES):\n",
    "    train_losses_dict = {}\n",
    "    val_losses_dict = {}\n",
    "\n",
    "    for sparsity in sparsity_levels:\n",
    "        print(\"\\n New Experiment Started....\")\n",
    "        dsd_model = DSDTraining(model, sparsity=sparsity)\n",
    "        set_all_seed(42)\n",
    "        train_costs, val_costs = train_dsd(dsd_model, EPOCH_DENSE1, EPOCH_SPARSE, EPOCH_DENSE2, NB_TRAIN_EXAMPLES, NB_VAL_EXAMPLES)\n",
    "\n",
    "        train_losses_dict[sparsity] = train_costs\n",
    "        val_losses_dict[sparsity] = val_costs\n",
    "\n",
    "    return train_losses_dict, val_losses_dict\n",
    "\n",
    "sparsity_levels = [0.001, 0.05, 0.5]\n",
    "\n",
    "train_losses_dict, val_losses_dict = experiment_vary_sparsity(model, sparsity_levels, EPOCH_DENSE1, EPOCH_SPARSE, EPOCH_DENSE2, NB_TRAIN_EXAMPLES, NB_VAL_EXAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d072fef6-4c4b-4a02-a325-446054d98c48",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Experiment-2: Epoch Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7ea44ef-85cc-4538-a523-d9787e8ee163",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   1    |   100   |   2.325611   |   0.103281   |     -      |     -      |    2.29   \n",
      "   1    |   200   |   2.302585   |   0.100469   |     -      |     -      |    2.25   \n",
      "   1    |   300   |   2.302585   |   0.097812   |     -      |     -      |    2.25   \n",
      "   1    |   400   |   2.302585   |   0.099219   |     -      |     -      |    2.28   \n",
      "   1    |   500   |   2.302585   |   0.102813   |     -      |     -      |    2.38   \n",
      "   1    |   600   |   2.302585   |   0.099687   |     -      |     -      |    2.25   \n",
      "   1    |   700   |   2.302585   |   0.099062   |     -      |     -      |    2.34   \n",
      "   1    |   703   |   1.630998   |   0.057292   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 1/13]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.32\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   2    |   100   |   2.325611   |   0.099531   |     -      |     -      |    2.27   \n",
      "   2    |   200   |   2.302585   |   0.103594   |     -      |     -      |    2.23   \n",
      "   2    |   300   |   2.302585   |   0.098750   |     -      |     -      |    2.30   \n",
      "   2    |   400   |   2.302585   |   0.105625   |     -      |     -      |    2.33   \n",
      "   2    |   500   |   2.302585   |   0.103281   |     -      |     -      |    2.29   \n",
      "   2    |   600   |   2.302585   |   0.095937   |     -      |     -      |    2.27   \n",
      "   2    |   700   |   2.302585   |   0.095781   |     -      |     -      |    2.33   \n",
      "   2    |   703   |   1.630998   |   0.052083   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 2/13]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.30\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   3    |   100   |   2.325611   |   0.104531   |     -      |     -      |    2.30   \n",
      "   3    |   200   |   2.302585   |   0.102813   |     -      |     -      |    2.26   \n",
      "   3    |   300   |   2.302585   |   0.098906   |     -      |     -      |    2.31   \n",
      "   3    |   400   |   2.302585   |   0.102188   |     -      |     -      |    2.28   \n",
      "   3    |   500   |   2.302585   |   0.097187   |     -      |     -      |    2.26   \n",
      "   3    |   600   |   2.302585   |   0.098281   |     -      |     -      |    2.63   \n",
      "   3    |   700   |   2.302585   |   0.097812   |     -      |     -      |    2.25   \n",
      "   3    |   703   |   1.630998   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 3/13]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.58\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   4    |   100   |   2.325611   |   0.102031   |     -      |     -      |    2.29   \n",
      "   4    |   200   |   2.302585   |   0.101094   |     -      |     -      |    2.24   \n",
      "   4    |   300   |   2.302585   |   0.100469   |     -      |     -      |    2.23   \n",
      "   4    |   400   |   2.302585   |   0.097656   |     -      |     -      |    2.26   \n",
      "   4    |   500   |   2.302585   |   0.092344   |     -      |     -      |    2.29   \n",
      "   4    |   600   |   2.302585   |   0.103594   |     -      |     -      |    2.25   \n",
      "   4    |   700   |   2.302585   |   0.104531   |     -      |     -      |    2.24   \n",
      "   4    |   703   |   1.630998   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 4/13]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.07\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   5    |   100   |   2.325611   |   0.100781   |     -      |     -      |    2.39   \n",
      "   5    |   200   |   2.302585   |   0.099062   |     -      |     -      |    2.29   \n",
      "   5    |   300   |   2.302585   |   0.094844   |     -      |     -      |    2.25   \n",
      "   5    |   400   |   2.302585   |   0.102344   |     -      |     -      |    2.25   \n",
      "   5    |   500   |   2.302585   |   0.101875   |     -      |     -      |    2.26   \n",
      "   5    |   600   |   2.302585   |   0.102500   |     -      |     -      |    2.30   \n",
      "   5    |   700   |   2.302585   |   0.100000   |     -      |     -      |    2.26   \n",
      "   5    |   703   |   1.630998   |   0.088542   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 5/13]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.32\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   6    |   100   |   2.325611   |   0.105313   |     -      |     -      |    2.31   \n",
      "   6    |   200   |   2.302585   |   0.094219   |     -      |     -      |    2.25   \n",
      "   6    |   300   |   2.302585   |   0.102500   |     -      |     -      |    2.25   \n",
      "   6    |   400   |   2.302585   |   0.103281   |     -      |     -      |    2.34   \n",
      "   6    |   500   |   2.302585   |   0.099375   |     -      |     -      |    2.29   \n",
      "   6    |   600   |   2.302585   |   0.100156   |     -      |     -      |    2.29   \n",
      "   6    |   700   |   2.302585   |   0.096719   |     -      |     -      |    2.35   \n",
      "   6    |   703   |   1.630998   |   0.083333   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 6/13]: train_on_sparse = True | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.35\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   7    |   100   |   2.325611   |   0.099531   |     -      |     -      |    2.29   \n",
      "   7    |   200   |   2.302585   |   0.098594   |     -      |     -      |    2.64   \n",
      "   7    |   300   |   2.302585   |   0.097812   |     -      |     -      |    2.25   \n",
      "   7    |   400   |   2.302585   |   0.098437   |     -      |     -      |    2.33   \n",
      "   7    |   500   |   2.302585   |   0.105156   |     -      |     -      |    2.28   \n",
      "   7    |   600   |   2.302585   |   0.101719   |     -      |     -      |    2.35   \n",
      "   7    |   700   |   2.302585   |   0.100781   |     -      |     -      |    2.26   \n",
      "   7    |   703   |   1.630998   |   0.067708   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 7/13]: train_on_sparse = True | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.70\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   8    |   100   |   2.325611   |   0.100312   |     -      |     -      |    2.30   \n",
      "   8    |   200   |   2.302585   |   0.097656   |     -      |     -      |    2.27   \n",
      "   8    |   300   |   2.302585   |   0.097344   |     -      |     -      |    2.26   \n",
      "   8    |   400   |   2.302585   |   0.099844   |     -      |     -      |    2.24   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   8    |   500   |   2.302585   |   0.106875   |     -      |     -      |    2.38   \n",
      "   8    |   600   |   2.302585   |   0.101250   |     -      |     -      |    2.28   \n",
      "   8    |   700   |   2.302585   |   0.099375   |     -      |     -      |    2.27   \n",
      "   8    |   703   |   1.630998   |   0.046875   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 8/13]: train_on_sparse = True | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.32\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   9    |   100   |   2.325611   |   0.098437   |     -      |     -      |    2.27   \n",
      "   9    |   200   |   2.302585   |   0.102656   |     -      |     -      |    2.26   \n",
      "   9    |   300   |   2.302585   |   0.102031   |     -      |     -      |    2.26   \n",
      "   9    |   400   |   2.302585   |   0.101250   |     -      |     -      |    2.25   \n",
      "   9    |   500   |   2.302585   |   0.094062   |     -      |     -      |    2.27   \n",
      "   9    |   600   |   2.302585   |   0.096250   |     -      |     -      |    2.27   \n",
      "   9    |   700   |   2.302585   |   0.107500   |     -      |     -      |    2.24   \n",
      "   9    |   703   |   1.630998   |   0.062500   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 9/13]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.11\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  10    |   100   |   2.325611   |   0.095469   |     -      |     -      |    2.26   \n",
      "  10    |   200   |   2.302585   |   0.105469   |     -      |     -      |    2.24   \n",
      "  10    |   300   |   2.302585   |   0.104063   |     -      |     -      |    2.38   \n",
      "  10    |   400   |   2.302585   |   0.094531   |     -      |     -      |    2.24   \n",
      "  10    |   500   |   2.302585   |   0.105625   |     -      |     -      |    2.61   \n",
      "  10    |   600   |   2.302585   |   0.100312   |     -      |     -      |    2.25   \n",
      "  10    |   700   |   2.302585   |   0.096719   |     -      |     -      |    2.23   \n",
      "  10    |   703   |   1.630998   |   0.062500   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 10/13]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.50\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  11    |   100   |   2.325611   |   0.102031   |     -      |     -      |    2.32   \n",
      "  11    |   200   |   2.302585   |   0.106406   |     -      |     -      |    2.35   \n",
      "  11    |   300   |   2.302585   |   0.103906   |     -      |     -      |    2.23   \n",
      "  11    |   400   |   2.302585   |   0.095469   |     -      |     -      |    2.29   \n",
      "  11    |   500   |   2.302585   |   0.095156   |     -      |     -      |    2.31   \n",
      "  11    |   600   |   2.302585   |   0.102969   |     -      |     -      |    2.25   \n",
      "  11    |   700   |   2.302585   |   0.096406   |     -      |     -      |    2.26   \n",
      "  11    |   703   |   1.630998   |   0.057292   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 11/13]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.30\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  12    |   100   |   2.325611   |   0.096719   |     -      |     -      |    2.35   \n",
      "  12    |   200   |   2.302585   |   0.104219   |     -      |     -      |    2.26   \n",
      "  12    |   300   |   2.302585   |   0.101406   |     -      |     -      |    2.31   \n",
      "  12    |   400   |   2.302585   |   0.099531   |     -      |     -      |    2.27   \n",
      "  12    |   500   |   2.302585   |   0.103750   |     -      |     -      |    2.25   \n",
      "  12    |   600   |   2.302585   |   0.096406   |     -      |     -      |    2.32   \n",
      "  12    |   700   |   2.302585   |   0.099687   |     -      |     -      |    2.27   \n",
      "  12    |   703   |   1.630998   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 12/13]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.33\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  13    |   100   |   2.325611   |   0.107344   |     -      |     -      |    2.27   \n",
      "  13    |   200   |   2.302585   |   0.097656   |     -      |     -      |    2.26   \n",
      "  13    |   300   |   2.302585   |   0.097500   |     -      |     -      |    2.25   \n",
      "  13    |   400   |   2.302585   |   0.102969   |     -      |     -      |    2.23   \n",
      "  13    |   500   |   2.302585   |   0.100469   |     -      |     -      |    2.24   \n",
      "  13    |   600   |   2.302585   |   0.096094   |     -      |     -      |    2.26   \n",
      "  13    |   700   |   2.302585   |   0.099687   |     -      |     -      |    2.49   \n",
      "  13    |   703   |   1.630998   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 13/13]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.34\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   1    |   100   |   2.325611   |   0.103281   |     -      |     -      |    2.67   \n",
      "   1    |   200   |   2.302585   |   0.100469   |     -      |     -      |    2.24   \n",
      "   1    |   300   |   2.302585   |   0.097812   |     -      |     -      |    2.23   \n",
      "   1    |   400   |   2.302585   |   0.099219   |     -      |     -      |    2.24   \n",
      "   1    |   500   |   2.302585   |   0.102813   |     -      |     -      |    2.26   \n",
      "   1    |   600   |   2.302585   |   0.099687   |     -      |     -      |    2.25   \n",
      "   1    |   700   |   2.302585   |   0.099062   |     -      |     -      |    2.27   \n",
      "   1    |   703   |   1.630998   |   0.057292   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 1/12]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.46\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   2    |   100   |   2.325611   |   0.099531   |     -      |     -      |    2.27   \n",
      "   2    |   200   |   2.302585   |   0.103594   |     -      |     -      |    2.28   \n",
      "   2    |   300   |   2.302585   |   0.098750   |     -      |     -      |    2.24   \n",
      "   2    |   400   |   2.302585   |   0.105625   |     -      |     -      |    2.26   \n",
      "   2    |   500   |   2.302585   |   0.103281   |     -      |     -      |    2.35   \n",
      "   2    |   600   |   2.302585   |   0.095937   |     -      |     -      |    2.25   \n",
      "   2    |   700   |   2.302585   |   0.095781   |     -      |     -      |    2.34   \n",
      "   2    |   703   |   1.630998   |   0.052083   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 2/12]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.29\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3    |   100   |   2.325611   |   0.104531   |     -      |     -      |    2.35   \n",
      "   3    |   200   |   2.302585   |   0.102813   |     -      |     -      |    2.28   \n",
      "   3    |   300   |   2.302585   |   0.098906   |     -      |     -      |    2.26   \n",
      "   3    |   400   |   2.302585   |   0.102188   |     -      |     -      |    2.26   \n",
      "   3    |   500   |   2.302585   |   0.097187   |     -      |     -      |    2.26   \n",
      "   3    |   600   |   2.302585   |   0.098281   |     -      |     -      |    2.25   \n",
      "   3    |   700   |   2.302585   |   0.097812   |     -      |     -      |    2.25   \n",
      "   3    |   703   |   1.630998   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 3/12]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.18\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   4    |   100   |   2.325611   |   0.102031   |     -      |     -      |    2.32   \n",
      "   4    |   200   |   2.302585   |   0.101094   |     -      |     -      |    2.24   \n",
      "   4    |   300   |   2.302585   |   0.100469   |     -      |     -      |    2.44   \n",
      "   4    |   400   |   2.302585   |   0.097656   |     -      |     -      |    2.25   \n",
      "   4    |   500   |   2.302585   |   0.092344   |     -      |     -      |    2.69   \n",
      "   4    |   600   |   2.302585   |   0.103594   |     -      |     -      |    2.24   \n",
      "   4    |   700   |   2.302585   |   0.104531   |     -      |     -      |    2.24   \n",
      "   4    |   703   |   1.630998   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 4/12]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.71\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   5    |   100   |   2.325611   |   0.100781   |     -      |     -      |    2.30   \n",
      "   5    |   200   |   2.302585   |   0.099062   |     -      |     -      |    2.24   \n",
      "   5    |   300   |   2.302585   |   0.094844   |     -      |     -      |    2.27   \n",
      "   5    |   400   |   2.302585   |   0.102344   |     -      |     -      |    2.25   \n",
      "   5    |   500   |   2.302585   |   0.101875   |     -      |     -      |    2.23   \n",
      "   5    |   600   |   2.302585   |   0.102500   |     -      |     -      |    2.24   \n",
      "   5    |   700   |   2.302585   |   0.100000   |     -      |     -      |    2.24   \n",
      "   5    |   703   |   1.630998   |   0.088542   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 5/12]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.06\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   6    |   100   |   2.325611   |   0.105313   |     -      |     -      |    2.41   \n",
      "   6    |   200   |   2.302585   |   0.094219   |     -      |     -      |    2.26   \n",
      "   6    |   300   |   2.302585   |   0.102500   |     -      |     -      |    2.24   \n",
      "   6    |   400   |   2.302585   |   0.103281   |     -      |     -      |    2.25   \n",
      "   6    |   500   |   2.302585   |   0.099375   |     -      |     -      |    2.29   \n",
      "   6    |   600   |   2.302585   |   0.100156   |     -      |     -      |    2.29   \n",
      "   6    |   700   |   2.302585   |   0.096719   |     -      |     -      |    2.28   \n",
      "   6    |   703   |   1.630998   |   0.083333   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 6/12]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.34\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   7    |   100   |   2.325611   |   0.099531   |     -      |     -      |    2.38   \n",
      "   7    |   200   |   2.302585   |   0.098594   |     -      |     -      |    2.30   \n",
      "   7    |   300   |   2.302585   |   0.097812   |     -      |     -      |    2.24   \n",
      "   7    |   400   |   2.302585   |   0.098437   |     -      |     -      |    2.38   \n",
      "   7    |   500   |   2.302585   |   0.105156   |     -      |     -      |    2.27   \n",
      "   7    |   600   |   2.302585   |   0.101719   |     -      |     -      |    2.36   \n",
      "   7    |   700   |   2.302585   |   0.100781   |     -      |     -      |    2.32   \n",
      "   7    |   703   |   1.630998   |   0.067708   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 7/12]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.89\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   8    |   100   |   2.325611   |   0.100312   |     -      |     -      |    2.35   \n",
      "   8    |   200   |   2.302585   |   0.097656   |     -      |     -      |    2.26   \n",
      "   8    |   300   |   2.302585   |   0.097344   |     -      |     -      |    2.26   \n",
      "   8    |   400   |   2.302585   |   0.099844   |     -      |     -      |    2.26   \n",
      "   8    |   500   |   2.302585   |   0.106875   |     -      |     -      |    2.26   \n",
      "   8    |   600   |   2.302585   |   0.101250   |     -      |     -      |    2.30   \n",
      "   8    |   700   |   2.302585   |   0.099375   |     -      |     -      |    2.25   \n",
      "   8    |   703   |   1.630998   |   0.046875   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 8/12]: train_on_sparse = True | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.26\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   9    |   100   |   2.325611   |   0.098437   |     -      |     -      |    2.31   \n",
      "   9    |   200   |   2.302585   |   0.102656   |     -      |     -      |    2.31   \n",
      "   9    |   300   |   2.302585   |   0.102031   |     -      |     -      |    2.27   \n",
      "   9    |   400   |   2.302585   |   0.101250   |     -      |     -      |    2.35   \n",
      "   9    |   500   |   2.302585   |   0.094062   |     -      |     -      |    2.31   \n",
      "   9    |   600   |   2.302585   |   0.096250   |     -      |     -      |    2.26   \n",
      "   9    |   700   |   2.302585   |   0.107500   |     -      |     -      |    2.25   \n",
      "   9    |   703   |   1.630998   |   0.062500   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 9/12]: train_on_sparse = True | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.36\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  10    |   100   |   2.325611   |   0.095469   |     -      |     -      |    2.32   \n",
      "  10    |   200   |   2.302585   |   0.105469   |     -      |     -      |    2.28   \n",
      "  10    |   300   |   2.302585   |   0.104063   |     -      |     -      |    2.26   \n",
      "  10    |   400   |   2.302585   |   0.094531   |     -      |     -      |    2.25   \n",
      "  10    |   500   |   2.302585   |   0.105625   |     -      |     -      |    2.25   \n",
      "  10    |   600   |   2.302585   |   0.100312   |     -      |     -      |    2.29   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10    |   700   |   2.302585   |   0.096719   |     -      |     -      |    2.27   \n",
      "  10    |   703   |   1.630998   |   0.062500   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 10/12]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.22\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  11    |   100   |   2.325611   |   0.102031   |     -      |     -      |    2.26   \n",
      "  11    |   200   |   2.302585   |   0.106406   |     -      |     -      |    2.30   \n",
      "  11    |   300   |   2.302585   |   0.103906   |     -      |     -      |    2.31   \n",
      "  11    |   400   |   2.302585   |   0.095469   |     -      |     -      |    2.60   \n",
      "  11    |   500   |   2.302585   |   0.095156   |     -      |     -      |    2.24   \n",
      "  11    |   600   |   2.302585   |   0.102969   |     -      |     -      |    2.23   \n",
      "  11    |   700   |   2.302585   |   0.096406   |     -      |     -      |    2.24   \n",
      "  11    |   703   |   1.630998   |   0.057292   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 11/12]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.43\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  12    |   100   |   2.325611   |   0.096719   |     -      |     -      |    2.33   \n",
      "  12    |   200   |   2.302585   |   0.104219   |     -      |     -      |    2.32   \n",
      "  12    |   300   |   2.302585   |   0.101406   |     -      |     -      |    2.27   \n",
      "  12    |   400   |   2.302585   |   0.099531   |     -      |     -      |    2.25   \n",
      "  12    |   500   |   2.302585   |   0.103750   |     -      |     -      |    2.24   \n",
      "  12    |   600   |   2.302585   |   0.096406   |     -      |     -      |    2.24   \n",
      "  12    |   700   |   2.302585   |   0.099687   |     -      |     -      |    2.25   \n",
      "  12    |   703   |   1.630998   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 12/12]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.25\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   1    |   100   |   2.325611   |   0.103281   |     -      |     -      |    2.30   \n",
      "   1    |   200   |   2.302585   |   0.100469   |     -      |     -      |    2.23   \n",
      "   1    |   300   |   2.302585   |   0.097812   |     -      |     -      |    2.29   \n",
      "   1    |   400   |   2.302585   |   0.099219   |     -      |     -      |    2.27   \n",
      "   1    |   500   |   2.302585   |   0.102813   |     -      |     -      |    2.29   \n",
      "   1    |   600   |   2.302585   |   0.099687   |     -      |     -      |    2.26   \n",
      "   1    |   700   |   2.302585   |   0.099062   |     -      |     -      |    2.25   \n",
      "   1    |   703   |   1.630998   |   0.057292   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 1/14]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.18\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   2    |   100   |   2.325611   |   0.099531   |     -      |     -      |    2.26   \n",
      "   2    |   200   |   2.302585   |   0.103594   |     -      |     -      |    2.22   \n",
      "   2    |   300   |   2.302585   |   0.098750   |     -      |     -      |    2.27   \n",
      "   2    |   400   |   2.302585   |   0.105625   |     -      |     -      |    2.27   \n",
      "   2    |   500   |   2.302585   |   0.103281   |     -      |     -      |    2.26   \n",
      "   2    |   600   |   2.302585   |   0.095937   |     -      |     -      |    2.36   \n",
      "   2    |   700   |   2.302585   |   0.095781   |     -      |     -      |    2.64   \n",
      "   2    |   703   |   1.630998   |   0.052083   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 2/14]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.54\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   3    |   100   |   2.325611   |   0.104531   |     -      |     -      |    2.25   \n",
      "   3    |   200   |   2.302585   |   0.102813   |     -      |     -      |    2.24   \n",
      "   3    |   300   |   2.302585   |   0.098906   |     -      |     -      |    2.26   \n",
      "   3    |   400   |   2.302585   |   0.102188   |     -      |     -      |    2.27   \n",
      "   3    |   500   |   2.302585   |   0.097187   |     -      |     -      |    2.23   \n",
      "   3    |   600   |   2.302585   |   0.098281   |     -      |     -      |    2.25   \n",
      "   3    |   700   |   2.302585   |   0.097812   |     -      |     -      |    2.26   \n",
      "   3    |   703   |   1.630998   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 3/14]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.06\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   4    |   100   |   2.325611   |   0.102031   |     -      |     -      |    2.27   \n",
      "   4    |   200   |   2.302585   |   0.101094   |     -      |     -      |    2.23   \n",
      "   4    |   300   |   2.302585   |   0.100469   |     -      |     -      |    2.25   \n",
      "   4    |   400   |   2.302585   |   0.097656   |     -      |     -      |    2.38   \n",
      "   4    |   500   |   2.302585   |   0.092344   |     -      |     -      |    2.31   \n",
      "   4    |   600   |   2.302585   |   0.103594   |     -      |     -      |    2.30   \n",
      "   4    |   700   |   2.302585   |   0.104531   |     -      |     -      |    2.31   \n",
      "   4    |   703   |   1.630998   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 4/14]: train_on_sparse = True | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.37\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   5    |   100   |   2.325611   |   0.100781   |     -      |     -      |    2.30   \n",
      "   5    |   200   |   2.302585   |   0.099062   |     -      |     -      |    2.25   \n",
      "   5    |   300   |   2.302585   |   0.094844   |     -      |     -      |    2.26   \n",
      "   5    |   400   |   2.302585   |   0.102344   |     -      |     -      |    2.31   \n",
      "   5    |   500   |   2.302585   |   0.101875   |     -      |     -      |    2.26   \n",
      "   5    |   600   |   2.302585   |   0.102500   |     -      |     -      |    2.25   \n",
      "   5    |   700   |   2.302585   |   0.100000   |     -      |     -      |    2.24   \n",
      "   5    |   703   |   1.630998   |   0.088542   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 5/14]: train_on_sparse = True | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.18\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6    |   100   |   2.325611   |   0.105313   |     -      |     -      |    2.27   \n",
      "   6    |   200   |   2.302585   |   0.094219   |     -      |     -      |    2.34   \n",
      "   6    |   300   |   2.302585   |   0.102500   |     -      |     -      |    2.64   \n",
      "   6    |   400   |   2.302585   |   0.103281   |     -      |     -      |    2.27   \n",
      "   6    |   500   |   2.302585   |   0.099375   |     -      |     -      |    2.32   \n",
      "   6    |   600   |   2.302585   |   0.100156   |     -      |     -      |    2.30   \n",
      "   6    |   700   |   2.302585   |   0.096719   |     -      |     -      |    2.27   \n",
      "   6    |   703   |   1.630998   |   0.083333   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 6/14]: train_on_sparse = True | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.70\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   7    |   100   |   2.325611   |   0.099531   |     -      |     -      |    2.27   \n",
      "   7    |   200   |   2.302585   |   0.098594   |     -      |     -      |    2.26   \n",
      "   7    |   300   |   2.302585   |   0.097812   |     -      |     -      |    2.24   \n",
      "   7    |   400   |   2.302585   |   0.098437   |     -      |     -      |    2.27   \n",
      "   7    |   500   |   2.302585   |   0.105156   |     -      |     -      |    2.26   \n",
      "   7    |   600   |   2.302585   |   0.101719   |     -      |     -      |    2.24   \n",
      "   7    |   700   |   2.302585   |   0.100781   |     -      |     -      |    2.23   \n",
      "   7    |   703   |   1.630998   |   0.067708   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 7/14]: train_on_sparse = True | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.05\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   8    |   100   |   2.325611   |   0.100312   |     -      |     -      |    2.33   \n",
      "   8    |   200   |   2.302585   |   0.097656   |     -      |     -      |    2.29   \n",
      "   8    |   300   |   2.302585   |   0.097344   |     -      |     -      |    2.23   \n",
      "   8    |   400   |   2.302585   |   0.099844   |     -      |     -      |    2.27   \n",
      "   8    |   500   |   2.302585   |   0.106875   |     -      |     -      |    2.27   \n",
      "   8    |   600   |   2.302585   |   0.101250   |     -      |     -      |    2.25   \n",
      "   8    |   700   |   2.302585   |   0.099375   |     -      |     -      |    2.25   \n",
      "   8    |   703   |   1.630998   |   0.046875   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 8/14]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.14\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   9    |   100   |   2.325611   |   0.098437   |     -      |     -      |    2.26   \n",
      "   9    |   200   |   2.302585   |   0.102656   |     -      |     -      |    2.22   \n",
      "   9    |   300   |   2.302585   |   0.102031   |     -      |     -      |    2.23   \n",
      "   9    |   400   |   2.302585   |   0.101250   |     -      |     -      |    2.31   \n",
      "   9    |   500   |   2.302585   |   0.094062   |     -      |     -      |    2.31   \n",
      "   9    |   600   |   2.302585   |   0.096250   |     -      |     -      |    2.31   \n",
      "   9    |   700   |   2.302585   |   0.107500   |     -      |     -      |    2.78   \n",
      "   9    |   703   |   1.630998   |   0.062500   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 9/14]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.73\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  10    |   100   |   2.325611   |   0.095469   |     -      |     -      |    2.27   \n",
      "  10    |   200   |   2.302585   |   0.105469   |     -      |     -      |    2.26   \n",
      "  10    |   300   |   2.302585   |   0.104063   |     -      |     -      |    2.26   \n",
      "  10    |   400   |   2.302585   |   0.094531   |     -      |     -      |    2.25   \n",
      "  10    |   500   |   2.302585   |   0.105625   |     -      |     -      |    2.35   \n",
      "  10    |   600   |   2.302585   |   0.100312   |     -      |     -      |    2.32   \n",
      "  10    |   700   |   2.302585   |   0.096719   |     -      |     -      |    2.31   \n",
      "  10    |   703   |   1.630998   |   0.062500   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 10/14]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.34\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  11    |   100   |   2.325611   |   0.102031   |     -      |     -      |    2.27   \n",
      "  11    |   200   |   2.302585   |   0.106406   |     -      |     -      |    2.23   \n",
      "  11    |   300   |   2.302585   |   0.103906   |     -      |     -      |    2.24   \n",
      "  11    |   400   |   2.302585   |   0.095469   |     -      |     -      |    2.25   \n",
      "  11    |   500   |   2.302585   |   0.095156   |     -      |     -      |    2.35   \n",
      "  11    |   600   |   2.302585   |   0.102969   |     -      |     -      |    2.29   \n",
      "  11    |   700   |   2.302585   |   0.096406   |     -      |     -      |    2.30   \n",
      "  11    |   703   |   1.630998   |   0.057292   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 11/14]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.24\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  12    |   100   |   2.325611   |   0.096719   |     -      |     -      |    2.27   \n",
      "  12    |   200   |   2.302585   |   0.104219   |     -      |     -      |    2.26   \n",
      "  12    |   300   |   2.302585   |   0.101406   |     -      |     -      |    2.26   \n",
      "  12    |   400   |   2.302585   |   0.099531   |     -      |     -      |    2.24   \n",
      "  12    |   500   |   2.302585   |   0.103750   |     -      |     -      |    2.24   \n",
      "  12    |   600   |   2.302585   |   0.096406   |     -      |     -      |    2.24   \n",
      "  12    |   700   |   2.302585   |   0.099687   |     -      |     -      |    2.26   \n",
      "  12    |   703   |   1.630998   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 12/14]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.06\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  13    |   100   |   2.325611   |   0.107344   |     -      |     -      |    2.29   \n",
      "  13    |   200   |   2.302585   |   0.097656   |     -      |     -      |    2.61   \n",
      "  13    |   300   |   2.302585   |   0.097500   |     -      |     -      |    2.34   \n",
      "  13    |   400   |   2.302585   |   0.102969   |     -      |     -      |    2.30   \n",
      "  13    |   500   |   2.302585   |   0.100469   |     -      |     -      |    2.32   \n",
      "  13    |   600   |   2.302585   |   0.096094   |     -      |     -      |    2.27   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  13    |   700   |   2.302585   |   0.099687   |     -      |     -      |    2.30   \n",
      "  13    |   703   |   1.630998   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 13/14]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.74\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  14    |   100   |   2.325611   |   0.099219   |     -      |     -      |    2.34   \n",
      "  14    |   200   |   2.302585   |   0.100781   |     -      |     -      |    2.33   \n",
      "  14    |   300   |   2.302585   |   0.100312   |     -      |     -      |    2.27   \n",
      "  14    |   400   |   2.302585   |   0.102031   |     -      |     -      |    2.24   \n",
      "  14    |   500   |   2.302585   |   0.098281   |     -      |     -      |    2.26   \n",
      "  14    |   600   |   2.302585   |   0.100469   |     -      |     -      |    2.28   \n",
      "  14    |   700   |   2.302585   |   0.100781   |     -      |     -      |    2.30   \n",
      "  14    |   703   |   1.630998   |   0.072917   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 14/14]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.30\n"
     ]
    }
   ],
   "source": [
    "# Function to perform DSD training with different epoch distributions\n",
    "def experiment_epoch_distributions(model, sparsity, epoch_distributions, NB_TRAIN_EXAMPLES, NB_VAL_EXAMPLES):\n",
    "    train_losses_dict = {}\n",
    "    val_losses_dict = {}\n",
    "\n",
    "    for dense_epochs, sparse_epochs in epoch_distributions:\n",
    "        EPOCH_DENSE1 = dense_epochs[0]\n",
    "        EPOCH_SPARSE = sparse_epochs[0]\n",
    "        EPOCH_DENSE2 = dense_epochs[1]\n",
    "\n",
    "        dsd_model = DSDTraining(model, sparsity=sparsity)\n",
    "        set_all_seed(42)\n",
    "        train_costs, val_costs = train_dsd(dsd_model, EPOCH_DENSE1, EPOCH_SPARSE, EPOCH_DENSE2, NB_TRAIN_EXAMPLES, NB_VAL_EXAMPLES)\n",
    "\n",
    "        train_losses_dict[(tuple(dense_epochs), tuple(sparse_epochs))] = train_costs\n",
    "        val_losses_dict[(tuple(dense_epochs), tuple(sparse_epochs))] = val_costs\n",
    "\n",
    "    return train_losses_dict, val_losses_dict\n",
    "\n",
    "# Define different epoch distributions to experiment with\n",
    "epoch_distributions = [\n",
    "    ([5, 5], [3]),  # Dense-Sparse-Dense\n",
    "    ([7, 3], [2]),  # Dense-Sparse-Dense\n",
    "    ([3, 7], [4]),  # Dense-Sparse-Dense\n",
    "]\n",
    "\n",
    "# Perform experiment\n",
    "train_losses_dict, val_losses_dict = experiment_epoch_distributions(model, sparsity=0.3, epoch_distributions=epoch_distributions, NB_TRAIN_EXAMPLES=NB_TRAIN_EXAMPLES, NB_VAL_EXAMPLES=NB_VAL_EXAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe7966b-b14f-4a71-bca3-00dd33c44964",
   "metadata": {},
   "source": [
    "#### Experiment-3 : Pruning Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6c8a809-42ea-4f79-8738-2f9f8ebbee10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   1    |   100   |   2.325611   |   0.103281   |     -      |     -      |    2.28   \n",
      "   1    |   200   |   2.302585   |   0.100469   |     -      |     -      |    2.35   \n",
      "   1    |   300   |   2.302585   |   0.097812   |     -      |     -      |    2.26   \n",
      "   1    |   400   |   2.302585   |   0.099219   |     -      |     -      |    2.25   \n",
      "   1    |   500   |   2.302585   |   0.102813   |     -      |     -      |    2.27   \n",
      "   1    |   600   |   2.302585   |   0.099687   |     -      |     -      |    2.23   \n",
      "   1    |   700   |   2.302585   |   0.099062   |     -      |     -      |    2.24   \n",
      "   1    |   703   |   1.630998   |   0.057292   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 1/13]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.50\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   2    |   100   |   2.325611   |   0.099531   |     -      |     -      |    2.33   \n",
      "   2    |   200   |   2.302585   |   0.103594   |     -      |     -      |    2.30   \n",
      "   2    |   300   |   2.302585   |   0.098750   |     -      |     -      |    2.26   \n",
      "   2    |   400   |   2.302585   |   0.105625   |     -      |     -      |    2.26   \n",
      "   2    |   500   |   2.302585   |   0.103281   |     -      |     -      |    2.26   \n",
      "   2    |   600   |   2.302585   |   0.095937   |     -      |     -      |    2.25   \n",
      "   2    |   700   |   2.302585   |   0.095781   |     -      |     -      |    2.26   \n",
      "   2    |   703   |   1.630998   |   0.052083   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 2/13]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.21\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   3    |   100   |   2.325611   |   0.104531   |     -      |     -      |    2.26   \n",
      "   3    |   200   |   2.302585   |   0.102813   |     -      |     -      |    2.26   \n",
      "   3    |   300   |   2.302585   |   0.098906   |     -      |     -      |    2.25   \n",
      "   3    |   400   |   2.302585   |   0.102188   |     -      |     -      |    2.25   \n",
      "   3    |   500   |   2.302585   |   0.097187   |     -      |     -      |    2.26   \n",
      "   3    |   600   |   2.302585   |   0.098281   |     -      |     -      |    2.25   \n",
      "   3    |   700   |   2.302585   |   0.097812   |     -      |     -      |    2.32   \n",
      "   3    |   703   |   1.630998   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 3/13]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.16\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   4    |   100   |   2.325611   |   0.102031   |     -      |     -      |    2.39   \n",
      "   4    |   200   |   2.302585   |   0.101094   |     -      |     -      |    2.25   \n",
      "   4    |   300   |   2.302585   |   0.100469   |     -      |     -      |    2.29   \n",
      "   4    |   400   |   2.302585   |   0.097656   |     -      |     -      |    2.24   \n",
      "   4    |   500   |   2.302585   |   0.092344   |     -      |     -      |    2.23   \n",
      "   4    |   600   |   2.302585   |   0.103594   |     -      |     -      |    2.25   \n",
      "   4    |   700   |   2.302585   |   0.104531   |     -      |     -      |    2.25   \n",
      "   4    |   703   |   1.630998   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 4/13]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.19\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   5    |   100   |   2.325611   |   0.100781   |     -      |     -      |    2.28   \n",
      "   5    |   200   |   2.302585   |   0.099062   |     -      |     -      |    2.27   \n",
      "   5    |   300   |   2.302585   |   0.094844   |     -      |     -      |    2.37   \n",
      "   5    |   400   |   2.302585   |   0.102344   |     -      |     -      |    2.54   \n",
      "   5    |   500   |   2.302585   |   0.101875   |     -      |     -      |    2.29   \n",
      "   5    |   600   |   2.302585   |   0.102500   |     -      |     -      |    2.25   \n",
      "   5    |   700   |   2.302585   |   0.100000   |     -      |     -      |    2.28   \n",
      "   5    |   703   |   1.630998   |   0.088542   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 5/13]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.57\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   6    |   100   |   2.325611   |   0.105313   |     -      |     -      |    2.30   \n",
      "   6    |   200   |   2.302585   |   0.094219   |     -      |     -      |    2.26   \n",
      "   6    |   300   |   2.302585   |   0.102500   |     -      |     -      |    2.29   \n",
      "   6    |   400   |   2.302585   |   0.103281   |     -      |     -      |    2.26   \n",
      "   6    |   500   |   2.302585   |   0.099375   |     -      |     -      |    2.27   \n",
      "   6    |   600   |   2.302585   |   0.100156   |     -      |     -      |    2.25   \n",
      "   6    |   700   |   2.302585   |   0.096719   |     -      |     -      |    2.25   \n",
      "   6    |   703   |   1.630998   |   0.083333   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 6/13]: train_on_sparse = True | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.18\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   7    |   100   |   2.325611   |   0.099531   |     -      |     -      |    2.28   \n",
      "   7    |   200   |   2.302585   |   0.098594   |     -      |     -      |    2.26   \n",
      "   7    |   300   |   2.302585   |   0.097812   |     -      |     -      |    2.33   \n",
      "   7    |   400   |   2.302585   |   0.098437   |     -      |     -      |    2.40   \n",
      "   7    |   500   |   2.302585   |   0.105156   |     -      |     -      |    2.29   \n",
      "   7    |   600   |   2.302585   |   0.101719   |     -      |     -      |    2.25   \n",
      "   7    |   700   |   2.302585   |   0.100781   |     -      |     -      |    2.25   \n",
      "   7    |   703   |   1.630998   |   0.067708   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 7/13]: train_on_sparse = True | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.40\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   8    |   100   |   2.325611   |   0.100312   |     -      |     -      |    2.31   \n",
      "   8    |   200   |   2.302585   |   0.097656   |     -      |     -      |    2.25   \n",
      "   8    |   300   |   2.302585   |   0.097344   |     -      |     -      |    2.25   \n",
      "   8    |   400   |   2.302585   |   0.099844   |     -      |     -      |    2.30   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   8    |   500   |   2.302585   |   0.106875   |     -      |     -      |    2.26   \n",
      "   8    |   600   |   2.302585   |   0.101250   |     -      |     -      |    2.30   \n",
      "   8    |   700   |   2.302585   |   0.099375   |     -      |     -      |    2.67   \n",
      "   8    |   703   |   1.630998   |   0.046875   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 8/13]: train_on_sparse = True | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.62\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "   9    |   100   |   2.325611   |   0.098437   |     -      |     -      |    2.36   \n",
      "   9    |   200   |   2.302585   |   0.102656   |     -      |     -      |    2.25   \n",
      "   9    |   300   |   2.302585   |   0.102031   |     -      |     -      |    2.27   \n",
      "   9    |   400   |   2.302585   |   0.101250   |     -      |     -      |    2.27   \n",
      "   9    |   500   |   2.302585   |   0.094062   |     -      |     -      |    2.27   \n",
      "   9    |   600   |   2.302585   |   0.096250   |     -      |     -      |    2.28   \n",
      "   9    |   700   |   2.302585   |   0.107500   |     -      |     -      |    2.28   \n",
      "   9    |   703   |   1.630998   |   0.062500   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 9/13]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.23\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  10    |   100   |   2.325611   |   0.095469   |     -      |     -      |    2.26   \n",
      "  10    |   200   |   2.302585   |   0.105469   |     -      |     -      |    2.23   \n",
      "  10    |   300   |   2.302585   |   0.104063   |     -      |     -      |    2.23   \n",
      "  10    |   400   |   2.302585   |   0.094531   |     -      |     -      |    2.27   \n",
      "  10    |   500   |   2.302585   |   0.105625   |     -      |     -      |    2.25   \n",
      "  10    |   600   |   2.302585   |   0.100312   |     -      |     -      |    2.23   \n",
      "  10    |   700   |   2.302585   |   0.096719   |     -      |     -      |    2.37   \n",
      "  10    |   703   |   1.630998   |   0.062500   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 10/13]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.25\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  11    |   100   |   2.325611   |   0.102031   |     -      |     -      |    2.29   \n",
      "  11    |   200   |   2.302585   |   0.106406   |     -      |     -      |    2.27   \n",
      "  11    |   300   |   2.302585   |   0.103906   |     -      |     -      |    2.24   \n",
      "  11    |   400   |   2.302585   |   0.095469   |     -      |     -      |    2.25   \n",
      "  11    |   500   |   2.302585   |   0.095156   |     -      |     -      |    2.28   \n",
      "  11    |   600   |   2.302585   |   0.102969   |     -      |     -      |    2.25   \n",
      "  11    |   700   |   2.302585   |   0.096406   |     -      |     -      |    2.24   \n",
      "  11    |   703   |   1.630998   |   0.057292   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 11/13]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.08\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  12    |   100   |   2.325611   |   0.096719   |     -      |     -      |    2.33   \n",
      "  12    |   200   |   2.302585   |   0.104219   |     -      |     -      |    2.32   \n",
      "  12    |   300   |   2.302585   |   0.101406   |     -      |     -      |    2.69   \n",
      "  12    |   400   |   2.302585   |   0.099531   |     -      |     -      |    2.25   \n",
      "  12    |   500   |   2.302585   |   0.103750   |     -      |     -      |    2.36   \n",
      "  12    |   600   |   2.302585   |   0.096406   |     -      |     -      |    2.27   \n",
      "  12    |   700   |   2.302585   |   0.099687   |     -      |     -      |    2.26   \n",
      "  12    |   703   |   1.630998   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 12/13]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.78\n",
      " Epoch  |  Batch  |  Train Loss  |  Train Acc   |  Val Loss  |  Val Acc   |  Elapsed \n",
      "-------------------------------------------------------------------------------------\n",
      "  13    |   100   |   2.325611   |   0.107344   |     -      |     -      |    2.31   \n",
      "  13    |   200   |   2.302585   |   0.097656   |     -      |     -      |    2.25   \n",
      "  13    |   300   |   2.302585   |   0.097500   |     -      |     -      |    2.34   \n",
      "  13    |   400   |   2.302585   |   0.102969   |     -      |     -      |    2.26   \n",
      "  13    |   500   |   2.302585   |   0.100469   |     -      |     -      |    2.29   \n",
      "  13    |   600   |   2.302585   |   0.096094   |     -      |     -      |    2.24   \n",
      "  13    |   700   |   2.302585   |   0.099687   |     -      |     -      |    2.24   \n",
      "  13    |   703   |   1.630998   |   0.078125   |     -      |     -      |    0.06   \n",
      "-------------------------------------------------------------------------------------\n",
      "[Epoch 13/13]: train_on_sparse = False | train-loss = 2.302585 | train-acc = 0.100133 | val-loss = 2.302585 | val-acc = 0.098800 | time_elapsed = 17.22\n",
      "Pruned Model: Loss = 2.302590847015381, Accuracy = 10.0%\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "def apply_pruning(model, pruning_method, amount):\n",
    "    # Prune model using specified method and amount\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            prune.l1_unstructured(module, name='weight', amount=amount)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def evaluate_pruned_model(pruned_model, data_loader, criterion):\n",
    "    pruned_model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = pruned_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return running_loss, accuracy\n",
    "\n",
    "# Train the model\n",
    "set_all_seed(42)\n",
    "train_costs, val_costs = train_dsd(dsd_model, EPOCH_DENSE1, EPOCH_SPARSE, EPOCH_DENSE2, NB_TRAIN_EXAMPLES, NB_VAL_EXAMPLES)\n",
    "\n",
    "# Apply pruning to the trained model\n",
    "pruning_method = 'l1_unstructured'\n",
    "amount = 0.2\n",
    "pruned_model = apply_pruning(dsd_model.model, pruning_method, amount)\n",
    "\n",
    "# Evaluate pruned model\n",
    "pruned_loss, pruned_accuracy = evaluate_pruned_model(pruned_model, test_loader, criterion)\n",
    "print(f\"Pruned Model: Loss = {pruned_loss}, Accuracy = {pruned_accuracy}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
